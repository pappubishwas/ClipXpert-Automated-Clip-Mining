{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nxdLFADTBdwY"
      },
      "source": [
        "**LAMA :  Language Model Analysis**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ynbvuqk5BtL4"
      },
      "source": [
        "# Downloading Audio File from YT link"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "eNKmZ5TqzME_",
        "outputId": "858cfb71-9555-4439-c17c-f7e3cd5e88dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting yt-dlp\n",
            "  Downloading yt_dlp-2024.8.6-py3-none-any.whl.metadata (170 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/170.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m163.8/170.1 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m170.1/170.1 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting pytube\n",
            "  Downloading pytube-15.0.0-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.42.4)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.23.5)\n",
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.10/dist-packages (1.0.3)\n",
            "Collecting langdetect\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting openai-whisper\n",
            "  Downloading openai-whisper-20231117.tar.gz (798 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m798.6/798.6 kB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting brotli (from yt-dlp)\n",
            "  Downloading Brotli-1.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from yt-dlp) (2024.7.4)\n",
            "Collecting mutagen (from yt-dlp)\n",
            "  Downloading mutagen-1.47.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting pycryptodomex (from yt-dlp)\n",
            "  Downloading pycryptodomex-3.20.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: requests<3,>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from yt-dlp) (2.32.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.26.17 in /usr/local/lib/python3.10/dist-packages (from yt-dlp) (2.0.7)\n",
            "Collecting websockets>=12.0 (from yt-dlp)\n",
            "  Downloading websockets-13.0.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.26.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.15.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.4)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2024.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.12.2)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.10/dist-packages (from moviepy) (4.4.2)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.1.10)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.10/dist-packages (from moviepy) (2.34.2)\n",
            "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.5.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from langdetect) (1.16.0)\n",
            "Collecting triton<3,>=2.0.0 (from openai-whisper)\n",
            "  Downloading triton-2.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (0.60.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (2.4.0+cu121)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (10.3.0)\n",
            "Collecting tiktoken (from openai-whisper)\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.10/dist-packages (from imageio<3.0,>=2.5->moviepy) (9.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from imageio-ffmpeg>=0.2.0->moviepy) (71.0.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.32.2->yt-dlp) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.32.2->yt-dlp) (3.8)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper) (0.43.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (3.1.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->openai-whisper) (1.3.0)\n",
            "Downloading yt_dlp-2024.8.6-py3-none-any.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m52.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Downloading pytube-15.0.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-2.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.1/168.1 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading websockets-13.0.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (157 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m157.3/157.3 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Brotli-1.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m55.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mutagen-1.47.0-py3-none-any.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.4/194.4 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pycryptodomex-3.20.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m45.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m35.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: langdetect, openai-whisper\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993221 sha256=8cb11695a8acf364279c90e9499a130c09f82b1ce7fad04619e83f35bb6f6783\n",
            "  Stored in directory: /root/.cache/pip/wheels/95/03/7d/59ea870c70ce4e5a370638b5462a7711ab78fba2f655d05106\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20231117-py3-none-any.whl size=801359 sha256=9db4505a65a64a2e164fe903f35e229bfafecdff014d84f501a88626233e84e9\n",
            "  Stored in directory: /root/.cache/pip/wheels/d0/85/e1/9361b4cbea7dd4b7f6702fa4c3afc94877952eeb2b62f45f56\n",
            "Successfully built langdetect openai-whisper\n",
            "Installing collected packages: pydub, brotli, websockets, triton, pytube, pycryptodomex, mutagen, langdetect, yt-dlp, tiktoken, openai-whisper\n",
            "Successfully installed brotli-1.1.0 langdetect-1.0.9 mutagen-1.47.0 openai-whisper-20231117 pycryptodomex-3.20.0 pydub-0.25.1 pytube-15.0.0 tiktoken-0.7.0 triton-2.3.1 websockets-13.0.1 yt-dlp-2024.8.6\n",
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Ign:3 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:5 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:6 https://r2u.stat.illinois.edu/ubuntu jammy Release [5,713 B]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:8 https://r2u.stat.illinois.edu/ubuntu jammy Release.gpg [793 B]\n",
            "Get:9 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [962 kB]\n",
            "Hit:10 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Get:11 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,264 kB]\n",
            "Hit:12 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,499 kB]\n",
            "Get:14 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease [24.3 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,221 kB]\n",
            "Hit:16 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,435 kB]\n",
            "Get:18 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,561 kB]\n",
            "Get:19 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy/main amd64 Packages [53.3 kB]\n",
            "Get:20 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,145 kB]\n",
            "Fetched 19.4 MB in 3s (7,296 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 50 not upgraded.\n",
            "Collecting pymongo\n",
            "  Downloading pymongo-4.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\n",
            "Collecting dnspython<3.0.0,>=1.16.0 (from pymongo)\n",
            "  Downloading dnspython-2.6.1-py3-none-any.whl.metadata (5.8 kB)\n",
            "Downloading pymongo-4.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dnspython-2.6.1-py3-none-any.whl (307 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: dnspython, pymongo\n",
            "Successfully installed dnspython-2.6.1 pymongo-4.8.0\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  fonts-droid-fallback fonts-noto-mono fonts-urw-base35 ghostscript gsfonts imagemagick-6-common\n",
            "  imagemagick-6.q16 libdjvulibre-text libdjvulibre21 libfftw3-double3 libgs9 libgs9-common libidn12\n",
            "  libijs-0.35 libjbig2dec0 libjxr-tools libjxr0 liblqr-1-0 libmagickcore-6.q16-6\n",
            "  libmagickcore-6.q16-6-extra libmagickwand-6.q16-6 libnetpbm10 libwmflite-0.2-7 netpbm\n",
            "  poppler-data\n",
            "Suggested packages:\n",
            "  fonts-noto fonts-freefont-otf | fonts-freefont-ttf fonts-texgyre ghostscript-x imagemagick-doc\n",
            "  autotrace cups-bsd | lpr | lprng enscript gimp gnuplot grads hp2xx html2ps libwmf-bin mplayer\n",
            "  povray radiance sane-utils texlive-base-bin transfig ufraw-batch libfftw3-bin libfftw3-dev\n",
            "  inkscape poppler-utils fonts-japanese-mincho | fonts-ipafont-mincho fonts-japanese-gothic\n",
            "  | fonts-ipafont-gothic fonts-arphic-ukai fonts-arphic-uming fonts-nanum\n",
            "The following NEW packages will be installed:\n",
            "  fonts-droid-fallback fonts-noto-mono fonts-urw-base35 ghostscript gsfonts imagemagick\n",
            "  imagemagick-6-common imagemagick-6.q16 libdjvulibre-text libdjvulibre21 libfftw3-double3 libgs9\n",
            "  libgs9-common libidn12 libijs-0.35 libjbig2dec0 libjxr-tools libjxr0 liblqr-1-0\n",
            "  libmagickcore-6.q16-6 libmagickcore-6.q16-6-extra libmagickwand-6.q16-6 libnetpbm10\n",
            "  libwmflite-0.2-7 netpbm poppler-data\n",
            "0 upgraded, 26 newly installed, 0 to remove and 50 not upgraded.\n",
            "Need to get 25.1 MB of archives.\n",
            "After this operation, 87.9 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-droid-fallback all 1:6.0.1r16-1.1build1 [1,805 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 libfftw3-double3 amd64 3.3.8-2ubuntu8 [770 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 liblqr-1-0 amd64 0.4.2-2.1 [27.7 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 imagemagick-6-common all 8:6.9.11.60+dfsg-1.3ubuntu0.22.04.5 [64.3 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libmagickcore-6.q16-6 amd64 8:6.9.11.60+dfsg-1.3ubuntu0.22.04.5 [1,795 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libmagickwand-6.q16-6 amd64 8:6.9.11.60+dfsg-1.3ubuntu0.22.04.5 [328 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy/main amd64 poppler-data all 0.4.11-1 [2,171 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-noto-mono all 20201225-1build1 [397 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-urw-base35 all 20200910-1 [6,367 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgs9-common all 9.55.0~dfsg1-0ubuntu5.9 [752 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libidn12 amd64 1.38-4ubuntu1 [60.0 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy/main amd64 libijs-0.35 amd64 0.35-15build2 [16.5 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy/main amd64 libjbig2dec0 amd64 0.19-3build2 [64.7 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgs9 amd64 9.55.0~dfsg1-0ubuntu5.9 [5,033 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 ghostscript amd64 9.55.0~dfsg1-0ubuntu5.9 [49.5 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy/universe amd64 gsfonts all 1:8.11+urwcyr1.0.7~pre44-4.5 [3,120 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 imagemagick-6.q16 amd64 8:6.9.11.60+dfsg-1.3ubuntu0.22.04.5 [224 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 imagemagick amd64 8:6.9.11.60+dfsg-1.3ubuntu0.22.04.5 [14.6 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy/main amd64 libdjvulibre-text all 3.5.28-2build2 [50.9 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu jammy/main amd64 libdjvulibre21 amd64 3.5.28-2build2 [624 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libjxr0 amd64 1.2~git20170615.f752187-5 [174 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libjxr-tools amd64 1.2~git20170615.f752187-5 [16.0 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu jammy/main amd64 libwmflite-0.2-7 amd64 0.2.12-5ubuntu1 [68.9 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libmagickcore-6.q16-6-extra amd64 8:6.9.11.60+dfsg-1.3ubuntu0.22.04.5 [70.1 kB]\n",
            "Get:25 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libnetpbm10 amd64 2:10.0-15.4 [59.1 kB]\n",
            "Get:26 http://archive.ubuntu.com/ubuntu jammy/universe amd64 netpbm amd64 2:10.0-15.4 [1,007 kB]\n",
            "Fetched 25.1 MB in 1s (18.7 MB/s)\n",
            "Selecting previously unselected package fonts-droid-fallback.\n",
            "(Reading database ... 123597 files and directories currently installed.)\n",
            "Preparing to unpack .../00-fonts-droid-fallback_1%3a6.0.1r16-1.1build1_all.deb ...\n",
            "Unpacking fonts-droid-fallback (1:6.0.1r16-1.1build1) ...\n",
            "Selecting previously unselected package libfftw3-double3:amd64.\n",
            "Preparing to unpack .../01-libfftw3-double3_3.3.8-2ubuntu8_amd64.deb ...\n",
            "Unpacking libfftw3-double3:amd64 (3.3.8-2ubuntu8) ...\n",
            "Selecting previously unselected package liblqr-1-0:amd64.\n",
            "Preparing to unpack .../02-liblqr-1-0_0.4.2-2.1_amd64.deb ...\n",
            "Unpacking liblqr-1-0:amd64 (0.4.2-2.1) ...\n",
            "Selecting previously unselected package imagemagick-6-common.\n",
            "Preparing to unpack .../03-imagemagick-6-common_8%3a6.9.11.60+dfsg-1.3ubuntu0.22.04.5_all.deb ...\n",
            "Unpacking imagemagick-6-common (8:6.9.11.60+dfsg-1.3ubuntu0.22.04.5) ...\n",
            "Selecting previously unselected package libmagickcore-6.q16-6:amd64.\n",
            "Preparing to unpack .../04-libmagickcore-6.q16-6_8%3a6.9.11.60+dfsg-1.3ubuntu0.22.04.5_amd64.deb ...\n",
            "Unpacking libmagickcore-6.q16-6:amd64 (8:6.9.11.60+dfsg-1.3ubuntu0.22.04.5) ...\n",
            "Selecting previously unselected package libmagickwand-6.q16-6:amd64.\n",
            "Preparing to unpack .../05-libmagickwand-6.q16-6_8%3a6.9.11.60+dfsg-1.3ubuntu0.22.04.5_amd64.deb ...\n",
            "Unpacking libmagickwand-6.q16-6:amd64 (8:6.9.11.60+dfsg-1.3ubuntu0.22.04.5) ...\n",
            "Selecting previously unselected package poppler-data.\n",
            "Preparing to unpack .../06-poppler-data_0.4.11-1_all.deb ...\n",
            "Unpacking poppler-data (0.4.11-1) ...\n",
            "Selecting previously unselected package fonts-noto-mono.\n",
            "Preparing to unpack .../07-fonts-noto-mono_20201225-1build1_all.deb ...\n",
            "Unpacking fonts-noto-mono (20201225-1build1) ...\n",
            "Selecting previously unselected package fonts-urw-base35.\n",
            "Preparing to unpack .../08-fonts-urw-base35_20200910-1_all.deb ...\n",
            "Unpacking fonts-urw-base35 (20200910-1) ...\n",
            "Selecting previously unselected package libgs9-common.\n",
            "Preparing to unpack .../09-libgs9-common_9.55.0~dfsg1-0ubuntu5.9_all.deb ...\n",
            "Unpacking libgs9-common (9.55.0~dfsg1-0ubuntu5.9) ...\n",
            "Selecting previously unselected package libidn12:amd64.\n",
            "Preparing to unpack .../10-libidn12_1.38-4ubuntu1_amd64.deb ...\n",
            "Unpacking libidn12:amd64 (1.38-4ubuntu1) ...\n",
            "Selecting previously unselected package libijs-0.35:amd64.\n",
            "Preparing to unpack .../11-libijs-0.35_0.35-15build2_amd64.deb ...\n",
            "Unpacking libijs-0.35:amd64 (0.35-15build2) ...\n",
            "Selecting previously unselected package libjbig2dec0:amd64.\n",
            "Preparing to unpack .../12-libjbig2dec0_0.19-3build2_amd64.deb ...\n",
            "Unpacking libjbig2dec0:amd64 (0.19-3build2) ...\n",
            "Selecting previously unselected package libgs9:amd64.\n",
            "Preparing to unpack .../13-libgs9_9.55.0~dfsg1-0ubuntu5.9_amd64.deb ...\n",
            "Unpacking libgs9:amd64 (9.55.0~dfsg1-0ubuntu5.9) ...\n",
            "Selecting previously unselected package ghostscript.\n",
            "Preparing to unpack .../14-ghostscript_9.55.0~dfsg1-0ubuntu5.9_amd64.deb ...\n",
            "Unpacking ghostscript (9.55.0~dfsg1-0ubuntu5.9) ...\n",
            "Selecting previously unselected package gsfonts.\n",
            "Preparing to unpack .../15-gsfonts_1%3a8.11+urwcyr1.0.7~pre44-4.5_all.deb ...\n",
            "Unpacking gsfonts (1:8.11+urwcyr1.0.7~pre44-4.5) ...\n",
            "Selecting previously unselected package imagemagick-6.q16.\n",
            "Preparing to unpack .../16-imagemagick-6.q16_8%3a6.9.11.60+dfsg-1.3ubuntu0.22.04.5_amd64.deb ...\n",
            "Unpacking imagemagick-6.q16 (8:6.9.11.60+dfsg-1.3ubuntu0.22.04.5) ...\n",
            "Selecting previously unselected package imagemagick.\n",
            "Preparing to unpack .../17-imagemagick_8%3a6.9.11.60+dfsg-1.3ubuntu0.22.04.5_amd64.deb ...\n",
            "Unpacking imagemagick (8:6.9.11.60+dfsg-1.3ubuntu0.22.04.5) ...\n",
            "Selecting previously unselected package libdjvulibre-text.\n",
            "Preparing to unpack .../18-libdjvulibre-text_3.5.28-2build2_all.deb ...\n",
            "Unpacking libdjvulibre-text (3.5.28-2build2) ...\n",
            "Selecting previously unselected package libdjvulibre21:amd64.\n",
            "Preparing to unpack .../19-libdjvulibre21_3.5.28-2build2_amd64.deb ...\n",
            "Unpacking libdjvulibre21:amd64 (3.5.28-2build2) ...\n",
            "Selecting previously unselected package libjxr0:amd64.\n",
            "Preparing to unpack .../20-libjxr0_1.2~git20170615.f752187-5_amd64.deb ...\n",
            "Unpacking libjxr0:amd64 (1.2~git20170615.f752187-5) ...\n",
            "Selecting previously unselected package libjxr-tools.\n",
            "Preparing to unpack .../21-libjxr-tools_1.2~git20170615.f752187-5_amd64.deb ...\n",
            "Unpacking libjxr-tools (1.2~git20170615.f752187-5) ...\n",
            "Selecting previously unselected package libwmflite-0.2-7:amd64.\n",
            "Preparing to unpack .../22-libwmflite-0.2-7_0.2.12-5ubuntu1_amd64.deb ...\n",
            "Unpacking libwmflite-0.2-7:amd64 (0.2.12-5ubuntu1) ...\n",
            "Selecting previously unselected package libmagickcore-6.q16-6-extra:amd64.\n",
            "Preparing to unpack .../23-libmagickcore-6.q16-6-extra_8%3a6.9.11.60+dfsg-1.3ubuntu0.22.04.5_amd64.deb ...\n",
            "Unpacking libmagickcore-6.q16-6-extra:amd64 (8:6.9.11.60+dfsg-1.3ubuntu0.22.04.5) ...\n",
            "Selecting previously unselected package libnetpbm10.\n",
            "Preparing to unpack .../24-libnetpbm10_2%3a10.0-15.4_amd64.deb ...\n",
            "Unpacking libnetpbm10 (2:10.0-15.4) ...\n",
            "Selecting previously unselected package netpbm.\n",
            "Preparing to unpack .../25-netpbm_2%3a10.0-15.4_amd64.deb ...\n",
            "Unpacking netpbm (2:10.0-15.4) ...\n",
            "Setting up imagemagick-6-common (8:6.9.11.60+dfsg-1.3ubuntu0.22.04.5) ...\n",
            "Setting up fonts-noto-mono (20201225-1build1) ...\n",
            "Setting up libwmflite-0.2-7:amd64 (0.2.12-5ubuntu1) ...\n",
            "Setting up libijs-0.35:amd64 (0.35-15build2) ...\n",
            "Setting up libjxr0:amd64 (1.2~git20170615.f752187-5) ...\n",
            "Setting up libnetpbm10 (2:10.0-15.4) ...\n",
            "Setting up fonts-urw-base35 (20200910-1) ...\n",
            "Setting up poppler-data (0.4.11-1) ...\n",
            "Setting up libjbig2dec0:amd64 (0.19-3build2) ...\n",
            "Setting up gsfonts (1:8.11+urwcyr1.0.7~pre44-4.5) ...\n",
            "Setting up libidn12:amd64 (1.38-4ubuntu1) ...\n",
            "Setting up netpbm (2:10.0-15.4) ...\n",
            "Setting up libfftw3-double3:amd64 (3.3.8-2ubuntu8) ...\n",
            "Setting up liblqr-1-0:amd64 (0.4.2-2.1) ...\n",
            "Setting up fonts-droid-fallback (1:6.0.1r16-1.1build1) ...\n",
            "Setting up libdjvulibre-text (3.5.28-2build2) ...\n",
            "Setting up libgs9-common (9.55.0~dfsg1-0ubuntu5.9) ...\n",
            "Setting up libjxr-tools (1.2~git20170615.f752187-5) ...\n",
            "Setting up libgs9:amd64 (9.55.0~dfsg1-0ubuntu5.9) ...\n",
            "Setting up libdjvulibre21:amd64 (3.5.28-2build2) ...\n",
            "Setting up ghostscript (9.55.0~dfsg1-0ubuntu5.9) ...\n",
            "Setting up libmagickcore-6.q16-6:amd64 (8:6.9.11.60+dfsg-1.3ubuntu0.22.04.5) ...\n",
            "Setting up libmagickwand-6.q16-6:amd64 (8:6.9.11.60+dfsg-1.3ubuntu0.22.04.5) ...\n",
            "Setting up libmagickcore-6.q16-6-extra:amd64 (8:6.9.11.60+dfsg-1.3ubuntu0.22.04.5) ...\n",
            "Setting up imagemagick-6.q16 (8:6.9.11.60+dfsg-1.3ubuntu0.22.04.5) ...\n",
            "update-alternatives: using /usr/bin/compare-im6.q16 to provide /usr/bin/compare (compare) in auto mode\n",
            "update-alternatives: using /usr/bin/compare-im6.q16 to provide /usr/bin/compare-im6 (compare-im6) in auto mode\n",
            "update-alternatives: using /usr/bin/animate-im6.q16 to provide /usr/bin/animate (animate) in auto mode\n",
            "update-alternatives: using /usr/bin/animate-im6.q16 to provide /usr/bin/animate-im6 (animate-im6) in auto mode\n",
            "update-alternatives: using /usr/bin/convert-im6.q16 to provide /usr/bin/convert (convert) in auto mode\n",
            "update-alternatives: using /usr/bin/convert-im6.q16 to provide /usr/bin/convert-im6 (convert-im6) in auto mode\n",
            "update-alternatives: using /usr/bin/composite-im6.q16 to provide /usr/bin/composite (composite) in auto mode\n",
            "update-alternatives: using /usr/bin/composite-im6.q16 to provide /usr/bin/composite-im6 (composite-im6) in auto mode\n",
            "update-alternatives: using /usr/bin/conjure-im6.q16 to provide /usr/bin/conjure (conjure) in auto mode\n",
            "update-alternatives: using /usr/bin/conjure-im6.q16 to provide /usr/bin/conjure-im6 (conjure-im6) in auto mode\n",
            "update-alternatives: using /usr/bin/import-im6.q16 to provide /usr/bin/import (import) in auto mode\n",
            "update-alternatives: using /usr/bin/import-im6.q16 to provide /usr/bin/import-im6 (import-im6) in auto mode\n",
            "update-alternatives: using /usr/bin/identify-im6.q16 to provide /usr/bin/identify (identify) in auto mode\n",
            "update-alternatives: using /usr/bin/identify-im6.q16 to provide /usr/bin/identify-im6 (identify-im6) in auto mode\n",
            "update-alternatives: using /usr/bin/stream-im6.q16 to provide /usr/bin/stream (stream) in auto mode\n",
            "update-alternatives: using /usr/bin/stream-im6.q16 to provide /usr/bin/stream-im6 (stream-im6) in auto mode\n",
            "update-alternatives: using /usr/bin/display-im6.q16 to provide /usr/bin/display (display) in auto mode\n",
            "update-alternatives: using /usr/bin/display-im6.q16 to provide /usr/bin/display-im6 (display-im6) in auto mode\n",
            "update-alternatives: using /usr/bin/montage-im6.q16 to provide /usr/bin/montage (montage) in auto mode\n",
            "update-alternatives: using /usr/bin/montage-im6.q16 to provide /usr/bin/montage-im6 (montage-im6) in auto mode\n",
            "update-alternatives: using /usr/bin/mogrify-im6.q16 to provide /usr/bin/mogrify (mogrify) in auto mode\n",
            "update-alternatives: using /usr/bin/mogrify-im6.q16 to provide /usr/bin/mogrify-im6 (mogrify-im6) in auto mode\n",
            "Setting up imagemagick (8:6.9.11.60+dfsg-1.3ubuntu0.22.04.5) ...\n",
            "Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n",
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.10/dist-packages (1.0.3)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.10/dist-packages (from moviepy) (4.4.2)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.10/dist-packages (from moviepy) (4.66.5)\n",
            "Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from moviepy) (2.32.3)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.1.10)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from moviepy) (1.26.4)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.10/dist-packages (from moviepy) (2.34.2)\n",
            "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.5.1)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.10/dist-packages (from imageio<3.0,>=2.5->moviepy) (9.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from imageio-ffmpeg>=0.2.0->moviepy) (71.0.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2024.7.4)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.5)\n",
            "Collecting playwright\n",
            "  Downloading playwright-1.46.0-py3-none-manylinux1_x86_64.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: greenlet==3.0.3 in /usr/local/lib/python3.10/dist-packages (from playwright) (3.0.3)\n",
            "Collecting pyee==11.1.0 (from playwright)\n",
            "  Downloading pyee-11.1.0-py3-none-any.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from pyee==11.1.0->playwright) (4.12.2)\n",
            "Downloading playwright-1.46.0-py3-none-manylinux1_x86_64.whl (37.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.9/37.9 MB\u001b[0m \u001b[31m40.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyee-11.1.0-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: pyee, playwright\n",
            "Successfully installed playwright-1.46.0 pyee-11.1.0\n",
            "Downloading Chromium 128.0.6613.18 (playwright build v1129)\u001b[2m from https://playwright.azureedge.net/builds/chromium/1129/chromium-linux.zip\u001b[22m\n",
            "\u001b[1G162.8 MiB [] 0% 0.0s\u001b[0K\u001b[1G162.8 MiB [] 0% 33.5s\u001b[0K\u001b[1G162.8 MiB [] 0% 20.8s\u001b[0K\u001b[1G162.8 MiB [] 0% 12.8s\u001b[0K\u001b[1G162.8 MiB [] 0% 11.2s\u001b[0K\u001b[1G162.8 MiB [] 1% 7.3s\u001b[0K\u001b[1G162.8 MiB [] 1% 5.4s\u001b[0K\u001b[1G162.8 MiB [] 2% 4.7s\u001b[0K\u001b[1G162.8 MiB [] 2% 4.6s\u001b[0K\u001b[1G162.8 MiB [] 3% 4.4s\u001b[0K\u001b[1G162.8 MiB [] 3% 4.0s\u001b[0K\u001b[1G162.8 MiB [] 4% 4.2s\u001b[0K\u001b[1G162.8 MiB [] 4% 4.0s\u001b[0K\u001b[1G162.8 MiB [] 5% 4.0s\u001b[0K\u001b[1G162.8 MiB [] 5% 3.7s\u001b[0K\u001b[1G162.8 MiB [] 6% 3.6s\u001b[0K\u001b[1G162.8 MiB [] 7% 3.4s\u001b[0K\u001b[1G162.8 MiB [] 8% 3.2s\u001b[0K\u001b[1G162.8 MiB [] 9% 3.2s\u001b[0K\u001b[1G162.8 MiB [] 9% 3.1s\u001b[0K\u001b[1G162.8 MiB [] 10% 3.1s\u001b[0K\u001b[1G162.8 MiB [] 11% 3.0s\u001b[0K\u001b[1G162.8 MiB [] 11% 2.9s\u001b[0K\u001b[1G162.8 MiB [] 11% 3.0s\u001b[0K\u001b[1G162.8 MiB [] 12% 3.1s\u001b[0K\u001b[1G162.8 MiB [] 12% 3.0s\u001b[0K\u001b[1G162.8 MiB [] 13% 3.0s\u001b[0K\u001b[1G162.8 MiB [] 14% 3.0s\u001b[0K\u001b[1G162.8 MiB [] 15% 2.8s\u001b[0K\u001b[1G162.8 MiB [] 15% 2.7s\u001b[0K\u001b[1G162.8 MiB [] 16% 2.7s\u001b[0K\u001b[1G162.8 MiB [] 17% 2.6s\u001b[0K\u001b[1G162.8 MiB [] 18% 2.5s\u001b[0K\u001b[1G162.8 MiB [] 19% 2.4s\u001b[0K\u001b[1G162.8 MiB [] 20% 2.4s\u001b[0K\u001b[1G162.8 MiB [] 20% 2.3s\u001b[0K\u001b[1G162.8 MiB [] 21% 2.3s\u001b[0K\u001b[1G162.8 MiB [] 22% 2.3s\u001b[0K\u001b[1G162.8 MiB [] 23% 2.2s\u001b[0K\u001b[1G162.8 MiB [] 24% 2.2s\u001b[0K\u001b[1G162.8 MiB [] 24% 2.3s\u001b[0K\u001b[1G162.8 MiB [] 25% 2.3s\u001b[0K\u001b[1G162.8 MiB [] 26% 2.2s\u001b[0K\u001b[1G162.8 MiB [] 27% 2.2s\u001b[0K\u001b[1G162.8 MiB [] 28% 2.1s\u001b[0K\u001b[1G162.8 MiB [] 29% 2.1s\u001b[0K\u001b[1G162.8 MiB [] 30% 2.0s\u001b[0K\u001b[1G162.8 MiB [] 31% 2.0s\u001b[0K\u001b[1G162.8 MiB [] 32% 1.9s\u001b[0K\u001b[1G162.8 MiB [] 33% 1.9s\u001b[0K\u001b[1G162.8 MiB [] 34% 1.8s\u001b[0K\u001b[1G162.8 MiB [] 35% 1.8s\u001b[0K\u001b[1G162.8 MiB [] 36% 1.8s\u001b[0K\u001b[1G162.8 MiB [] 37% 1.7s\u001b[0K\u001b[1G162.8 MiB [] 38% 1.7s\u001b[0K\u001b[1G162.8 MiB [] 39% 1.6s\u001b[0K\u001b[1G162.8 MiB [] 40% 1.6s\u001b[0K\u001b[1G162.8 MiB [] 41% 1.5s\u001b[0K\u001b[1G162.8 MiB [] 42% 1.5s\u001b[0K\u001b[1G162.8 MiB [] 43% 1.5s\u001b[0K\u001b[1G162.8 MiB [] 44% 1.4s\u001b[0K\u001b[1G162.8 MiB [] 45% 1.4s\u001b[0K\u001b[1G162.8 MiB [] 46% 1.4s\u001b[0K\u001b[1G162.8 MiB [] 46% 1.3s\u001b[0K\u001b[1G162.8 MiB [] 48% 1.3s\u001b[0K\u001b[1G162.8 MiB [] 49% 1.2s\u001b[0K\u001b[1G162.8 MiB [] 50% 1.2s\u001b[0K\u001b[1G162.8 MiB [] 51% 1.2s\u001b[0K\u001b[1G162.8 MiB [] 52% 1.1s\u001b[0K\u001b[1G162.8 MiB [] 53% 1.1s\u001b[0K\u001b[1G162.8 MiB [] 54% 1.1s\u001b[0K\u001b[1G162.8 MiB [] 55% 1.1s\u001b[0K\u001b[1G162.8 MiB [] 57% 1.0s\u001b[0K\u001b[1G162.8 MiB [] 58% 1.0s\u001b[0K\u001b[1G162.8 MiB [] 59% 0.9s\u001b[0K\u001b[1G162.8 MiB [] 60% 0.9s\u001b[0K\u001b[1G162.8 MiB [] 62% 0.9s\u001b[0K\u001b[1G162.8 MiB [] 63% 0.8s\u001b[0K\u001b[1G162.8 MiB [] 64% 0.8s\u001b[0K\u001b[1G162.8 MiB [] 65% 0.8s\u001b[0K\u001b[1G162.8 MiB [] 67% 0.7s\u001b[0K\u001b[1G162.8 MiB [] 68% 0.7s\u001b[0K\u001b[1G162.8 MiB [] 69% 0.7s\u001b[0K\u001b[1G162.8 MiB [] 70% 0.6s\u001b[0K\u001b[1G162.8 MiB [] 71% 0.6s\u001b[0K\u001b[1G162.8 MiB [] 72% 0.6s\u001b[0K\u001b[1G162.8 MiB [] 73% 0.6s\u001b[0K\u001b[1G162.8 MiB [] 74% 0.6s\u001b[0K\u001b[1G162.8 MiB [] 75% 0.5s\u001b[0K\u001b[1G162.8 MiB [] 76% 0.5s\u001b[0K\u001b[1G162.8 MiB [] 77% 0.5s\u001b[0K\u001b[1G162.8 MiB [] 78% 0.5s\u001b[0K\u001b[1G162.8 MiB [] 79% 0.4s\u001b[0K\u001b[1G162.8 MiB [] 80% 0.4s\u001b[0K\u001b[1G162.8 MiB [] 81% 0.4s\u001b[0K\u001b[1G162.8 MiB [] 82% 0.4s\u001b[0K\u001b[1G162.8 MiB [] 83% 0.3s\u001b[0K\u001b[1G162.8 MiB [] 84% 0.3s\u001b[0K\u001b[1G162.8 MiB [] 85% 0.3s\u001b[0K\u001b[1G162.8 MiB [] 86% 0.3s\u001b[0K\u001b[1G162.8 MiB [] 87% 0.3s\u001b[0K\u001b[1G162.8 MiB [] 88% 0.3s\u001b[0K\u001b[1G162.8 MiB [] 88% 0.2s\u001b[0K\u001b[1G162.8 MiB [] 89% 0.2s\u001b[0K\u001b[1G162.8 MiB [] 90% 0.2s\u001b[0K\u001b[1G162.8 MiB [] 91% 0.2s\u001b[0K\u001b[1G162.8 MiB [] 92% 0.2s\u001b[0K\u001b[1G162.8 MiB [] 93% 0.2s\u001b[0K\u001b[1G162.8 MiB [] 94% 0.1s\u001b[0K\u001b[1G162.8 MiB [] 95% 0.1s\u001b[0K\u001b[1G162.8 MiB [] 96% 0.1s\u001b[0K\u001b[1G162.8 MiB [] 97% 0.1s\u001b[0K\u001b[1G162.8 MiB [] 97% 0.0s\u001b[0K\u001b[1G162.8 MiB [] 98% 0.0s\u001b[0K\u001b[1G162.8 MiB [] 99% 0.0s\u001b[0K\u001b[1G162.8 MiB [] 100% 0.0s\u001b[0K\n",
            "Chromium 128.0.6613.18 (playwright build v1129) downloaded to /root/.cache/ms-playwright/chromium-1129\n",
            "Downloading FFMPEG playwright build v1009\u001b[2m from https://playwright.azureedge.net/builds/ffmpeg/1009/ffmpeg-linux.zip\u001b[22m\n",
            "\u001b[1G2.6 MiB [] 0% 0.0s\u001b[0K\u001b[1G2.6 MiB [] 3% 0.5s\u001b[0K\u001b[1G2.6 MiB [] 10% 0.3s\u001b[0K\u001b[1G2.6 MiB [] 29% 0.1s\u001b[0K\u001b[1G2.6 MiB [] 67% 0.0s\u001b[0K\u001b[1G2.6 MiB [] 100% 0.0s\u001b[0K\n",
            "FFMPEG playwright build v1009 downloaded to /root/.cache/ms-playwright/ffmpeg-1009\n",
            "Downloading Firefox 128.0 (playwright build v1458)\u001b[2m from https://playwright.azureedge.net/builds/firefox/1458/firefox-ubuntu-22.04.zip\u001b[22m\n",
            "\u001b[1G85.6 MiB [] 0% 0.0s\u001b[0K\u001b[1G85.6 MiB [] 0% 14.7s\u001b[0K\u001b[1G85.6 MiB [] 0% 10.0s\u001b[0K\u001b[1G85.6 MiB [] 1% 4.8s\u001b[0K\u001b[1G85.6 MiB [] 2% 3.0s\u001b[0K\u001b[1G85.6 MiB [] 3% 2.3s\u001b[0K\u001b[1G85.6 MiB [] 4% 2.1s\u001b[0K\u001b[1G85.6 MiB [] 5% 2.1s\u001b[0K\u001b[1G85.6 MiB [] 5% 2.0s\u001b[0K\u001b[1G85.6 MiB [] 6% 2.0s\u001b[0K\u001b[1G85.6 MiB [] 7% 1.9s\u001b[0K\u001b[1G85.6 MiB [] 8% 1.9s\u001b[0K\u001b[1G85.6 MiB [] 10% 1.7s\u001b[0K\u001b[1G85.6 MiB [] 11% 1.6s\u001b[0K\u001b[1G85.6 MiB [] 12% 1.6s\u001b[0K\u001b[1G85.6 MiB [] 13% 1.6s\u001b[0K\u001b[1G85.6 MiB [] 14% 1.5s\u001b[0K\u001b[1G85.6 MiB [] 16% 1.4s\u001b[0K\u001b[1G85.6 MiB [] 17% 1.4s\u001b[0K\u001b[1G85.6 MiB [] 18% 1.3s\u001b[0K\u001b[1G85.6 MiB [] 19% 1.3s\u001b[0K\u001b[1G85.6 MiB [] 21% 1.2s\u001b[0K\u001b[1G85.6 MiB [] 22% 1.2s\u001b[0K\u001b[1G85.6 MiB [] 24% 1.2s\u001b[0K\u001b[1G85.6 MiB [] 25% 1.1s\u001b[0K\u001b[1G85.6 MiB [] 27% 1.1s\u001b[0K\u001b[1G85.6 MiB [] 29% 1.0s\u001b[0K\u001b[1G85.6 MiB [] 30% 1.0s\u001b[0K\u001b[1G85.6 MiB [] 31% 1.0s\u001b[0K\u001b[1G85.6 MiB [] 33% 0.9s\u001b[0K\u001b[1G85.6 MiB [] 35% 0.9s\u001b[0K\u001b[1G85.6 MiB [] 37% 0.8s\u001b[0K\u001b[1G85.6 MiB [] 38% 0.8s\u001b[0K\u001b[1G85.6 MiB [] 39% 0.8s\u001b[0K\u001b[1G85.6 MiB [] 40% 0.8s\u001b[0K\u001b[1G85.6 MiB [] 42% 0.8s\u001b[0K\u001b[1G85.6 MiB [] 44% 0.7s\u001b[0K\u001b[1G85.6 MiB [] 45% 0.7s\u001b[0K\u001b[1G85.6 MiB [] 47% 0.7s\u001b[0K\u001b[1G85.6 MiB [] 48% 0.7s\u001b[0K\u001b[1G85.6 MiB [] 50% 0.6s\u001b[0K\u001b[1G85.6 MiB [] 52% 0.6s\u001b[0K\u001b[1G85.6 MiB [] 53% 0.6s\u001b[0K\u001b[1G85.6 MiB [] 55% 0.6s\u001b[0K\u001b[1G85.6 MiB [] 57% 0.5s\u001b[0K\u001b[1G85.6 MiB [] 59% 0.5s\u001b[0K\u001b[1G85.6 MiB [] 61% 0.5s\u001b[0K\u001b[1G85.6 MiB [] 63% 0.5s\u001b[0K\u001b[1G85.6 MiB [] 64% 0.4s\u001b[0K\u001b[1G85.6 MiB [] 66% 0.4s\u001b[0K\u001b[1G85.6 MiB [] 68% 0.4s\u001b[0K\u001b[1G85.6 MiB [] 69% 0.4s\u001b[0K\u001b[1G85.6 MiB [] 70% 0.4s\u001b[0K\u001b[1G85.6 MiB [] 72% 0.3s\u001b[0K\u001b[1G85.6 MiB [] 74% 0.3s\u001b[0K\u001b[1G85.6 MiB [] 75% 0.3s\u001b[0K\u001b[1G85.6 MiB [] 77% 0.3s\u001b[0K\u001b[1G85.6 MiB [] 79% 0.3s\u001b[0K\u001b[1G85.6 MiB [] 80% 0.2s\u001b[0K\u001b[1G85.6 MiB [] 82% 0.2s\u001b[0K\u001b[1G85.6 MiB [] 83% 0.2s\u001b[0K\u001b[1G85.6 MiB [] 85% 0.2s\u001b[0K\u001b[1G85.6 MiB [] 86% 0.2s\u001b[0K\u001b[1G85.6 MiB [] 88% 0.1s\u001b[0K\u001b[1G85.6 MiB [] 89% 0.1s\u001b[0K\u001b[1G85.6 MiB [] 91% 0.1s\u001b[0K\u001b[1G85.6 MiB [] 93% 0.1s\u001b[0K\u001b[1G85.6 MiB [] 94% 0.1s\u001b[0K\u001b[1G85.6 MiB [] 95% 0.1s\u001b[0K\u001b[1G85.6 MiB [] 97% 0.0s\u001b[0K\u001b[1G85.6 MiB [] 99% 0.0s\u001b[0K\u001b[1G85.6 MiB [] 100% 0.0s\u001b[0K\n",
            "Firefox 128.0 (playwright build v1458) downloaded to /root/.cache/ms-playwright/firefox-1458\n",
            "Downloading Webkit 18.0 (playwright build v2051)\u001b[2m from https://playwright.azureedge.net/builds/webkit/2051/webkit-ubuntu-22.04.zip\u001b[22m\n",
            "\u001b[1G87.3 MiB [] 0% 0.0s\u001b[0K\u001b[1G87.3 MiB [] 0% 20.2s\u001b[0K\u001b[1G87.3 MiB [] 0% 12.7s\u001b[0K\u001b[1G87.3 MiB [] 0% 7.9s\u001b[0K\u001b[1G87.3 MiB [] 1% 4.2s\u001b[0K\u001b[1G87.3 MiB [] 2% 3.0s\u001b[0K\u001b[1G87.3 MiB [] 3% 2.5s\u001b[0K\u001b[1G87.3 MiB [] 4% 2.2s\u001b[0K\u001b[1G87.3 MiB [] 5% 2.1s\u001b[0K\u001b[1G87.3 MiB [] 6% 2.0s\u001b[0K\u001b[1G87.3 MiB [] 8% 1.9s\u001b[0K\u001b[1G87.3 MiB [] 8% 1.8s\u001b[0K\u001b[1G87.3 MiB [] 10% 1.7s\u001b[0K\u001b[1G87.3 MiB [] 11% 1.6s\u001b[0K\u001b[1G87.3 MiB [] 13% 1.5s\u001b[0K\u001b[1G87.3 MiB [] 14% 1.5s\u001b[0K\u001b[1G87.3 MiB [] 15% 1.4s\u001b[0K\u001b[1G87.3 MiB [] 17% 1.3s\u001b[0K\u001b[1G87.3 MiB [] 19% 1.3s\u001b[0K\u001b[1G87.3 MiB [] 20% 1.2s\u001b[0K\u001b[1G87.3 MiB [] 21% 1.2s\u001b[0K\u001b[1G87.3 MiB [] 23% 1.2s\u001b[0K\u001b[1G87.3 MiB [] 24% 1.2s\u001b[0K\u001b[1G87.3 MiB [] 25% 1.1s\u001b[0K\u001b[1G87.3 MiB [] 27% 1.0s\u001b[0K\u001b[1G87.3 MiB [] 29% 1.0s\u001b[0K\u001b[1G87.3 MiB [] 30% 1.0s\u001b[0K\u001b[1G87.3 MiB [] 32% 0.9s\u001b[0K\u001b[1G87.3 MiB [] 34% 0.9s\u001b[0K\u001b[1G87.3 MiB [] 36% 0.9s\u001b[0K\u001b[1G87.3 MiB [] 38% 0.8s\u001b[0K\u001b[1G87.3 MiB [] 40% 0.8s\u001b[0K\u001b[1G87.3 MiB [] 41% 0.7s\u001b[0K\u001b[1G87.3 MiB [] 43% 0.7s\u001b[0K\u001b[1G87.3 MiB [] 44% 0.7s\u001b[0K\u001b[1G87.3 MiB [] 45% 0.7s\u001b[0K\u001b[1G87.3 MiB [] 46% 0.7s\u001b[0K\u001b[1G87.3 MiB [] 48% 0.7s\u001b[0K\u001b[1G87.3 MiB [] 50% 0.6s\u001b[0K\u001b[1G87.3 MiB [] 52% 0.6s\u001b[0K\u001b[1G87.3 MiB [] 54% 0.6s\u001b[0K\u001b[1G87.3 MiB [] 55% 0.6s\u001b[0K\u001b[1G87.3 MiB [] 57% 0.5s\u001b[0K\u001b[1G87.3 MiB [] 59% 0.5s\u001b[0K\u001b[1G87.3 MiB [] 61% 0.5s\u001b[0K\u001b[1G87.3 MiB [] 63% 0.4s\u001b[0K\u001b[1G87.3 MiB [] 65% 0.4s\u001b[0K\u001b[1G87.3 MiB [] 67% 0.4s\u001b[0K\u001b[1G87.3 MiB [] 69% 0.4s\u001b[0K\u001b[1G87.3 MiB [] 71% 0.3s\u001b[0K\u001b[1G87.3 MiB [] 73% 0.3s\u001b[0K\u001b[1G87.3 MiB [] 76% 0.3s\u001b[0K\u001b[1G87.3 MiB [] 78% 0.2s\u001b[0K\u001b[1G87.3 MiB [] 80% 0.2s\u001b[0K\u001b[1G87.3 MiB [] 82% 0.2s\u001b[0K\u001b[1G87.3 MiB [] 84% 0.2s\u001b[0K\u001b[1G87.3 MiB [] 86% 0.2s\u001b[0K\u001b[1G87.3 MiB [] 88% 0.1s\u001b[0K\u001b[1G87.3 MiB [] 91% 0.1s\u001b[0K\u001b[1G87.3 MiB [] 93% 0.1s\u001b[0K\u001b[1G87.3 MiB [] 95% 0.0s\u001b[0K\u001b[1G87.3 MiB [] 97% 0.0s\u001b[0K\u001b[1G87.3 MiB [] 98% 0.0s\u001b[0K\u001b[1G87.3 MiB [] 100% 0.0s\u001b[0K\n",
            "Webkit 18.0 (playwright build v2051) downloaded to /root/.cache/ms-playwright/webkit-2051\n",
            "Playwright Host validation warning: \n",
            "╔══════════════════════════════════════════════════════╗\n",
            "║ Host system is missing dependencies to run browsers. ║\n",
            "║ Missing libraries:                                   ║\n",
            "║     libwoff2dec.so.1.0.2                             ║\n",
            "║     libgstgl-1.0.so.0                                ║\n",
            "║     libgstcodecparsers-1.0.so.0                      ║\n",
            "║     libharfbuzz-icu.so.0                             ║\n",
            "║     libenchant-2.so.2                                ║\n",
            "║     libsecret-1.so.0                                 ║\n",
            "║     libhyphen.so.0                                   ║\n",
            "║     libmanette-0.2.so.0                              ║\n",
            "╚══════════════════════════════════════════════════════╝\n",
            "    at validateDependenciesLinux (/usr/local/lib/python3.10/dist-packages/playwright/driver/package/lib/server/registry/dependencies.js:216:9)\n",
            "\u001b[90m    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)\u001b[39m\n",
            "    at async Registry._validateHostRequirements (/usr/local/lib/python3.10/dist-packages/playwright/driver/package/lib/server/registry/index.js:575:43)\n",
            "    at async Registry._validateHostRequirementsForExecutableIfNeeded (/usr/local/lib/python3.10/dist-packages/playwright/driver/package/lib/server/registry/index.js:673:7)\n",
            "    at async Registry.validateHostRequirementsForExecutablesIfNeeded (/usr/local/lib/python3.10/dist-packages/playwright/driver/package/lib/server/registry/index.js:662:43)\n",
            "    at async t.<anonymous> (/usr/local/lib/python3.10/dist-packages/playwright/driver/package/lib/cli/program.js:119:7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.1.4)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "# Install necessary Python packages\n",
        "!pip install yt-dlp pydub pytube opencv-python transformers huggingface_hub moviepy langdetect openai-whisper\n",
        "\n",
        "# Install system package ffmpeg\n",
        "!apt-get update && apt-get install -y ffmpeg\n",
        "!pip install pymongo\n",
        "!apt-get install -y imagemagick\n",
        "\n",
        "# Upgrade moviepy\n",
        "!pip install --upgrade moviepy\n",
        "\n",
        "# Install additional Python packages\n",
        "!pip install nltk\n",
        "!pip install playwright\n",
        "!playwright install\n",
        "!pip install pandas\n",
        "!pip install torch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fBUeDJ-MEkjd"
      },
      "outputs": [],
      "source": [
        "with open('/etc/ImageMagick-6/policy.xml', 'w') as f:\n",
        "    f.write('''\n",
        "    <?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
        "    <policymap>\n",
        "      <policy domain=\"path\" rights=\"read|write\" pattern=\"@*\" />\n",
        "      <policy domain=\"path\" rights=\"read|write\" pattern=\"*\" />\n",
        "      <policy domain=\"system\" rights=\"read|write\" pattern=\"*\" />\n",
        "      <policy domain=\"resource\" name=\"memory\" value=\"2GiB\" />\n",
        "      <policy domain=\"resource\" name=\"map\" value=\"2GiB\" />\n",
        "      <policy domain=\"resource\" name=\"disk\" value=\"5GiB\" />\n",
        "      <policy domain=\"resource\" name=\"file\" value=\"768\" />\n",
        "      <policy domain=\"resource\" name=\"thread\" value=\"8\" />\n",
        "    </policymap>\n",
        "    ''')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NAeFXn8eA8Za"
      },
      "outputs": [],
      "source": [
        "import yt_dlp\n",
        "import json\n",
        "import whisper\n",
        "from io import BytesIO\n",
        "import numpy as np\n",
        "from moviepy.editor import VideoFileClip, TextClip, CompositeVideoClip, concatenate_videoclips\n",
        "from IPython.display import Video, display\n",
        "from pymongo import MongoClient\n",
        "from pydub import AudioSegment\n",
        "import os\n",
        "import tempfile\n",
        "import nltk\n",
        "from collections import Counter\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tag import pos_tag\n",
        "import nest_asyncio\n",
        "from playwright.async_api import async_playwright\n",
        "import asyncio\n",
        "import pandas as pd\n",
        "from transformers import pipeline\n",
        "import csv\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MATBBZO92EW1"
      },
      "source": [
        "# Creating Highlighted Videos\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRFap_N-BSV2"
      },
      "source": [
        "Download video from youtube"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TY7pqzCoZc3Q"
      },
      "outputs": [],
      "source": [
        "def download_video_yt_dlp(url, output_file_name):\n",
        "    ydl_opts = {\n",
        "        'format': 'best',\n",
        "        'outtmpl': output_file_name,\n",
        "    }\n",
        "    try:\n",
        "        with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "            ydl.download([url])\n",
        "        print(\"Download video complete!\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxA67JPvBV7e"
      },
      "source": [
        "Funtion for formatting the transcripted text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mHOJuo9rJSnL"
      },
      "outputs": [],
      "source": [
        "def format_with_timestamps(result, file_name):\n",
        "    formatted_segments = []\n",
        "    for segment in result.get(\"segments\", []):\n",
        "        segment_data = {\n",
        "            \"id\": segment.get(\"id\"),\n",
        "            \"start\": round(segment.get(\"start\", 0), 2),\n",
        "            \"end\": round(segment.get(\"end\", 0), 2),\n",
        "            \"text\": segment.get(\"text\", \"\")\n",
        "        }\n",
        "        formatted_segments.append(segment_data)\n",
        "\n",
        "    # Save to a JSON file\n",
        "    with open(file_name, 'w') as json_file:\n",
        "        json.dump(formatted_segments, json_file, indent=4)\n",
        "    print(\"Formatted subtitles created and saved\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E4h3FgcjBdef"
      },
      "source": [
        "Transcripted from audio to text by this function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X7PWwKFIjBYB"
      },
      "outputs": [],
      "source": [
        "\n",
        "def process_video_to_audio(video_file_name, subtitle_file):\n",
        "    # Remove the extension from the video file name\n",
        "    base_name = os.path.splitext(video_file_name)[0]\n",
        "\n",
        "    # Construct paths\n",
        "    video_path = f'/content/{video_file_name}'\n",
        "    audio_file = f'/content/{base_name}_audio.wav'\n",
        "\n",
        "    # Extract audio from the video file using pydub\n",
        "    audio = AudioSegment.from_file(video_path, format=\"mp4\")\n",
        "\n",
        "    # Save the audio to a WAV file (recommended for Whisper)\n",
        "    audio.export(audio_file, format=\"wav\")\n",
        "\n",
        "    # Load the Whisper model\n",
        "    model = whisper.load_model(\"base\")\n",
        "\n",
        "    # Transcribe the audio using Whisper\n",
        "    result = model.transcribe(audio_file)\n",
        "\n",
        "    print(\"Subtitle created by Whisper\")\n",
        "    print(result)\n",
        "\n",
        "    # Format and save the transcription with timestamps\n",
        "    format_with_timestamps(result, subtitle_file)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sOJBfSO0BnBB"
      },
      "source": [
        "Search the keyword from the transcripted text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sAHo5mA1ZZ9X"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def search_words_in_transcription(formatted_segments_file, search_words):\n",
        "    search_words = [word.lower() for word in search_words]\n",
        "    segments_with_words = []\n",
        "\n",
        "    try:\n",
        "        with open(formatted_segments_file, 'r') as file:\n",
        "            formatted_segments = json.load(file)\n",
        "    except FileNotFoundError:\n",
        "        raise FileNotFoundError(f\"The file {formatted_segments_file} was not found.\")\n",
        "    except json.JSONDecodeError:\n",
        "        raise ValueError(f\"Error decoding JSON from the file {formatted_segments_file}.\")\n",
        "\n",
        "    if not isinstance(formatted_segments, list):\n",
        "        raise ValueError(\"Expected formatted_segments to be a list of dictionaries.\")\n",
        "    if not all(isinstance(seg, dict) for seg in formatted_segments):\n",
        "        raise ValueError(\"Each item in formatted_segments should be a dictionary.\")\n",
        "\n",
        "    for segment in formatted_segments:\n",
        "        if \"text\" in segment:\n",
        "            text = segment[\"text\"].lower()\n",
        "            if any(word in text for word in search_words):\n",
        "                id = segment.get(\"id\", len(segments_with_words) + 1)\n",
        "                start = segment.get(\"start\")\n",
        "                end = segment.get(\"end\")\n",
        "                segments_with_words.append({\n",
        "                    \"id\": id,\n",
        "                    \"start_time\": start,  # Renaming \"start\" to \"start_time\"\n",
        "                    \"end_time\": end,      # Renaming \"end\" to \"end_time\"\n",
        "                    \"text\": segment[\"text\"]\n",
        "                })\n",
        "\n",
        "    # Check if segments_with_words is empty before saving\n",
        "    if not segments_with_words:\n",
        "        print(\"No matching words were found in the transcription. No file will be created.\")\n",
        "        return False\n",
        "\n",
        "    return segments_with_words\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-s6q19xwB1iS"
      },
      "source": [
        "Function for Creating the video based on keyword"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CBmrYsTRmXsU"
      },
      "outputs": [],
      "source": [
        "def create_highlight_video(original_video_path, highlighted_sections):\n",
        "    clips = []\n",
        "    original_video_path = '/content/' + original_video_path\n",
        "\n",
        "    # Load the original video\n",
        "    video = VideoFileClip(original_video_path)\n",
        "\n",
        "    for segment in highlighted_sections:\n",
        "        start = max(segment[\"start_time\"], 0)\n",
        "        end = min(segment[\"end_time\"], video.duration)\n",
        "\n",
        "        # Extract the clip\n",
        "        clip = video.subclip(start, end)\n",
        "\n",
        "        # Ensure clip is valid\n",
        "        #print(f\"Processing segment: {start}-{end} (Duration: {clip.duration})\")\n",
        "\n",
        "        # Create a TextClip for the corresponding text (subtitle) with white bold text and lighter black background\n",
        "        text = segment[\"text\"]\n",
        "        text_clip = TextClip(\n",
        "            text, fontsize=14, font='Arial-Bold', color='white', bg_color='#2c2c2c',  # Lighter dark gray\n",
        "            method='caption', size=(clip.w, None)\n",
        "        ).set_duration(clip.duration).set_position((\"center\", \"bottom\")).set_opacity(0.6)  # Reduced opacity for transparency\n",
        "\n",
        "        # Overlay the subtitle onto the video clip\n",
        "        video_with_subtitle = CompositeVideoClip([clip, text_clip])\n",
        "\n",
        "        # Add the video with subtitles to the clips list\n",
        "        clips.append(video_with_subtitle)\n",
        "\n",
        "    # Concatenate all clips into a single video\n",
        "    if clips:\n",
        "        final_video = concatenate_videoclips(clips, method=\"compose\")\n",
        "\n",
        "        # Create a temporary file to save the video\n",
        "        with tempfile.NamedTemporaryFile(delete=False, suffix=\".mp4\") as temp_file:\n",
        "            temp_file_name = temp_file.name\n",
        "            final_video.write_videofile(temp_file_name, codec=\"libx264\", audio_codec=\"aac\", fps=30)\n",
        "\n",
        "        # Display the video\n",
        "        print(\"Displaying the highlight video:\")\n",
        "        display(Video(temp_file_name, width=640, height=480, embed=True))\n",
        "\n",
        "        # Clean up the temporary file\n",
        "        os.remove(temp_file_name)\n",
        "    else:\n",
        "        print(\"No valid segments found to create the highlight video.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_YOJLxyCS3e"
      },
      "source": [
        "Connection with mongodb database"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wT5EVfQLrid3"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Replace with your MongoDB connection string\n",
        "connection_string = \"mongodb+srv:cluster0.wg4rh.mongodb.net/?retryWrites=true&w=majority&appName=Cluster0\"\n",
        "# Initialize MongoDB client and access database\n",
        "client = MongoClient(connection_string)\n",
        "db = client['youtube_video_details']\n",
        "videos_collection = db['video_information']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TmMaNuOZCfmA"
      },
      "source": [
        "Deleting the temporary file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5aBO3PgFiPLP"
      },
      "outputs": [],
      "source": [
        "def delete_all_files_in_directory(directory='/content/'):\n",
        "    # Check if the directory exists\n",
        "    if os.path.exists(directory):\n",
        "        # Loop through all files and subdirectories\n",
        "        for filename in os.listdir(directory):\n",
        "            file_path = os.path.join(directory, filename)\n",
        "\n",
        "            # Check if it's a file or directory\n",
        "            if os.path.isfile(file_path) or os.path.islink(file_path):\n",
        "                os.unlink(file_path)  # Delete the file\n",
        "            elif os.path.isdir(file_path):\n",
        "                shutil.rmtree(file_path)  # Delete the directory\n",
        "\n",
        "        print(f\"All files and directories in {directory} have been deleted.\")\n",
        "    else:\n",
        "        print(f\"The directory {directory} does not exist.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4OuqlxcCo23"
      },
      "source": [
        "Extract the highlighted section"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e84QCOX7bbd8"
      },
      "outputs": [],
      "source": [
        "def extract_highlighted_sections(highlighted_subtitle_file):\n",
        "    highlighted_sections = []\n",
        "    for entry in highlighted_subtitle_file:\n",
        "        highlighted_sections.append({\n",
        "            \"start_time\": entry.get(\"start_time\"),\n",
        "            \"end_time\": entry.get(\"end_time\"),\n",
        "            \"text\": entry.get(\"text\")\n",
        "        })\n",
        "    return highlighted_sections\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HzxdPnAbCuV7"
      },
      "source": [
        "Main function for creating the highlighted video from the given user keywords and youtube video url , finally store data in Mongodb database"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qbhnoCdE0p8X"
      },
      "outputs": [],
      "source": [
        "def create_video_json():\n",
        "    video_url = input(\"Enter the video URL: \")\n",
        "    keywords = [keyword.strip() for keyword in input(\"Enter keywords (comma-separated): \").split(',')]\n",
        "\n",
        "    existing_video = videos_collection.find_one({\"video_url\": video_url})\n",
        "\n",
        "    if not existing_video:\n",
        "        unique_id = videos_collection.count_documents({}) + 1\n",
        "        subtitle_file = f\"subtitle.json\"\n",
        "        video_file_name = f\"video.mp4\"\n",
        "\n",
        "        # Download and process the video\n",
        "        download_video_yt_dlp(video_url, video_file_name)\n",
        "        process_video_to_audio(video_file_name, subtitle_file)\n",
        "\n",
        "        # Search for keywords in transcription\n",
        "        #highlighted_subtitle_files = f\"highlighted_video_{unique_id}_1.json\"\n",
        "        highlighted_subtitle_files = search_words_in_transcription(subtitle_file, keywords)\n",
        "\n",
        "        if not highlighted_subtitle_files:\n",
        "            return\n",
        "\n",
        "        # Extract highlighted sections from the subtitle file\n",
        "        highlighted_sections = extract_highlighted_sections(highlighted_subtitle_files)\n",
        "\n",
        "        # Create highlight video using the extracted sections\n",
        "        create_highlight_video(video_file_name, highlighted_sections)\n",
        "\n",
        "        # Create the new video entry in the required format\n",
        "        new_video = {\n",
        "            \"video_url\": video_url,\n",
        "            \"details\": [\n",
        "                {\n",
        "                    \"keywords\": [\n",
        "                        {\n",
        "                            \"keyword\": keywords,\n",
        "                            \"highlighted_sections\": highlighted_sections\n",
        "                        }\n",
        "                    ]\n",
        "                }\n",
        "            ]\n",
        "        }\n",
        "\n",
        "        # Insert the new video document into the collection\n",
        "        videos_collection.insert_one(new_video)\n",
        "        print(f\"New entry added with unique ID: {unique_id}\")\n",
        "\n",
        "\n",
        "    else:\n",
        "        unique_id = existing_video['_id']\n",
        "        video_file_name = f\"video.mp4\"\n",
        "        subtitle_file = f\"subtitle.json\"\n",
        "        existing_details = existing_video['details'][0]\n",
        "\n",
        "        updated = False\n",
        "\n",
        "        # Check if the keywords already exist in the video entry\n",
        "        for keyword_entry in existing_details['keywords']:\n",
        "            if set(keyword_entry['keyword']) == set(keywords):\n",
        "                print(\"Keywords match existing entry.\")\n",
        "                # Download and process the video\n",
        "                download_video_yt_dlp(video_url, video_file_name)\n",
        "                highlighted_sections = keyword_entry['highlighted_sections']\n",
        "                create_highlight_video(video_file_name, highlighted_sections)\n",
        "                return\n",
        "\n",
        "        # Download and process the video\n",
        "        download_video_yt_dlp(video_url, video_file_name)\n",
        "        process_video_to_audio(video_file_name, subtitle_file)\n",
        "\n",
        "        # If the keywords don't match, process new highlighted sections\n",
        "        #new_highlighted_files = f\"highlighted_video_{unique_id}_{len(existing_details['keywords']) + 1}.json\"\n",
        "        new_highlighted_files = search_words_in_transcription(subtitle_file, keywords)\n",
        "\n",
        "        print(new_highlighted_files)\n",
        "        if not new_highlighted_files:\n",
        "            return\n",
        "\n",
        "        # Extract highlighted sections for the new keywords\n",
        "        highlighted_sections = extract_highlighted_sections(new_highlighted_files)\n",
        "        print(highlighted_sections)\n",
        "        # Create highlight video using the new highlighted sections\n",
        "        create_highlight_video(video_file_name, highlighted_sections)\n",
        "        print(f\"New entry added for keywords: {keywords} with highlighted files: {new_highlighted_files}\")\n",
        "\n",
        "        new_keywords = [{\n",
        "            \"keyword\": keywords,  # Storing all keywords as a list\n",
        "            \"highlighted_sections\": highlighted_sections\n",
        "        }]\n",
        "\n",
        "        # Update the document by appending the new keywords and highlighted sections\n",
        "        videos_collection.update_one(\n",
        "            {\"_id\": unique_id},\n",
        "            {\"$push\": {\"details.0.keywords\": {\"$each\": new_keywords}}}\n",
        "        )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWPzYYn0DBpT"
      },
      "source": [
        "Calling the main function and calculating the total time taken"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tNQMCYnyb09y"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "start_time = time.time()\n",
        "create_video_json()# Call for mongodb storage\n",
        "end_time = time.time()  # Capture the end time\n",
        "execution_time = end_time - start_time  # Calculate the total execution time\n",
        "print(f\"Total execution time: {execution_time:.2f} seconds\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0VFhUosDxji"
      },
      "source": [
        "Checking frame rate in the video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LizShXvKDw5Z",
        "outputId": "09a69769-173b-463b-b440-d6b4c6c28878"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Frame rate: 29.97002997002997 fps\n",
            "Number of frames in one second: 29.97002997002997\n"
          ]
        }
      ],
      "source": [
        "from moviepy.editor import VideoFileClip\n",
        "\n",
        "def get_frame_rate(video_path):\n",
        "    video = VideoFileClip(video_path)\n",
        "    return video.fps\n",
        "\n",
        "# Path to the video file\n",
        "video_path = '/content/video.mp4'\n",
        "\n",
        "frame_rate = get_frame_rate(video_path)\n",
        "print(f\"Frame rate: {frame_rate} fps\")\n",
        "print(f\"Number of frames in one second: {frame_rate}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCLCPWJcDNY0"
      },
      "source": [
        "# Use XML and json file storage system instead of Mongodb for comparing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ZSl5fqON8EY"
      },
      "outputs": [],
      "source": [
        "# Call the function\n",
        "# #delete_all_files_in_directory('/content/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q3P2dMNvN78P"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import xml.etree.ElementTree as ET\n",
        "import os\n",
        "\n",
        "# Utility function to save data to a JSON file\n",
        "def save_to_json(filename, data):\n",
        "    with open(filename, 'w') as f:\n",
        "        json.dump(data, f, indent=4)\n",
        "\n",
        "# Utility function to load all data from a JSON file\n",
        "def load_all_from_json(filename):\n",
        "    if os.path.exists(filename):\n",
        "        with open(filename, 'r') as f:\n",
        "            try:\n",
        "                data = json.load(f)\n",
        "                if isinstance(data, dict):  # Single video entry case\n",
        "                    return [data]\n",
        "                elif isinstance(data, list):  # List of video entries case\n",
        "                    return data\n",
        "            except json.JSONDecodeError as e:\n",
        "                print(f\"Error loading JSON file: {e}\")\n",
        "                return []\n",
        "    else:\n",
        "        print(f\"{filename} file not found\")\n",
        "        return []\n",
        "\n",
        "# Utility function to save data to an XML file\n",
        "def save_to_xml(filename, data):\n",
        "    root = ET.Element('Videos')\n",
        "\n",
        "    for video_data in data:\n",
        "        video_elem = ET.SubElement(root, 'Video')\n",
        "        ET.SubElement(video_elem, 'URL').text = video_data['video_url']\n",
        "\n",
        "        details_elem = ET.SubElement(video_elem, 'Details')\n",
        "        for detail in video_data['details']:\n",
        "            for keyword_data in detail['keywords']:\n",
        "                keyword_elem = ET.SubElement(details_elem, 'Keyword')\n",
        "                keyword_text = ','.join(keyword_data['keyword'])\n",
        "                ET.SubElement(keyword_elem, 'Text').text = keyword_text\n",
        "                sections_elem = ET.SubElement(keyword_elem, 'HighlightedSections')\n",
        "                for section in keyword_data['highlighted_sections']:\n",
        "                    section_elem = ET.SubElement(sections_elem, 'Section')\n",
        "                    ET.SubElement(section_elem, 'StartTime').text = str(section['start_time'])\n",
        "                    ET.SubElement(section_elem, 'EndTime').text = str(section['end_time'])\n",
        "                    ET.SubElement(section_elem, 'Text').text = section['text']\n",
        "\n",
        "    tree = ET.ElementTree(root)\n",
        "    tree.write(filename)\n",
        "\n",
        "def load_all_from_xml(filename, input_keywords, video_url):\n",
        "    if not os.path.exists(filename):\n",
        "        print(f\"{filename} file not found\")\n",
        "        return []\n",
        "\n",
        "    try:\n",
        "        tree = ET.parse(filename)\n",
        "        root = tree.getroot()\n",
        "\n",
        "        data = []\n",
        "        input_keywords_set = set([k.strip().lower() for k in input_keywords])  # Normalize input keywords\n",
        "\n",
        "        # Loop through each Video element in the XML\n",
        "        for video_elem in root.findall('Video'):\n",
        "            # Check if the video URL matches the input video_url\n",
        "            video_elem_url = video_elem.findtext('URL')\n",
        "            if video_elem_url == video_url:\n",
        "                video_data = {\"video_url\": video_elem_url, \"details\": []}\n",
        "\n",
        "                # Loop through each Keyword in the Details section\n",
        "                for keyword_elem in video_elem.findall('Details/Keyword'):\n",
        "                    xml_keywords = keyword_elem.findtext('Text').split(',')  # Split XML keywords\n",
        "                    xml_keywords_set = set([k.strip().lower() for k in xml_keywords])  # Normalize case and whitespace\n",
        "\n",
        "                    # Check if the input keywords match exactly with the XML keywords set\n",
        "                    if xml_keywords_set == input_keywords_set:\n",
        "                        highlighted_sections = []\n",
        "                        # Loop through each Section and extract highlighted sections\n",
        "                        for section_elem in keyword_elem.findall('HighlightedSections/Section'):\n",
        "                            highlighted_sections.append({\n",
        "                                'start_time': float(section_elem.findtext('StartTime')),\n",
        "                                'end_time': float(section_elem.findtext('EndTime')),\n",
        "                                'text': section_elem.findtext('Text')\n",
        "                            })\n",
        "                        # Add the matching keyword and its highlighted sections to the details\n",
        "                        video_data['details'].append({\n",
        "                            \"keywords\": [{\"keyword\": xml_keywords, \"highlighted_sections\": highlighted_sections}]\n",
        "                        })\n",
        "\n",
        "                # If details were found, add the video data to the result list\n",
        "                if video_data['details']:\n",
        "                    data.append(video_data)\n",
        "\n",
        "                # Exit the loop since the video URL has already matched\n",
        "                break\n",
        "\n",
        "        return data\n",
        "    except ET.ParseError as e:\n",
        "        print(f\"Error loading XML file: {e}\")\n",
        "        return []\n",
        "\n",
        "# Main function to handle video processing\n",
        "def create_video_json_or_xml(storage_format='json'):\n",
        "    video_url = input(\"Enter the video URL: \")\n",
        "    keywords = [keyword.strip() for keyword in input(\"Enter keywords (comma-separated): \").split(',')]\n",
        "\n",
        "    # Determine file type based on storage format\n",
        "    video_data_file = f\"videos.{storage_format}\"\n",
        "\n",
        "    # Load existing data based on the storage format\n",
        "    if storage_format == 'json':\n",
        "        existing_videos = load_all_from_json(video_data_file)\n",
        "    else:\n",
        "        existing_videos = load_all_from_xml(video_data_file,keywords,video_url)\n",
        "\n",
        "    # Check if the video URL already exists in the loaded data\n",
        "    existing_video_entry = next((v for v in existing_videos if v['video_url'] == video_url), None)\n",
        "    print(existing_video_entry)\n",
        "    if existing_video_entry:\n",
        "        existing_details = existing_video_entry['details'][0]\n",
        "\n",
        "        # Check if the keywords already exist in the video entry\n",
        "        for keyword_entry in existing_details['keywords']:\n",
        "            if set(keyword_entry['keyword']) == set(keywords):\n",
        "                print(\"Keywords match existing entry.\")\n",
        "                # Create highlight video for the existing keywords\n",
        "                video_file_name = f\"video_{storage_format}.mp4\"\n",
        "                download_video_yt_dlp(video_url, video_file_name)\n",
        "                create_highlight_video(video_file_name, keyword_entry['highlighted_sections'])\n",
        "                return\n",
        "\n",
        "        # If keywords don't match, process the new keywords\n",
        "        subtitle_file = f\"subtitle_{storage_format}.json\"\n",
        "        download_video_yt_dlp(video_url, f\"video_{storage_format}.mp4\")\n",
        "        process_video_to_audio(f\"video_{storage_format}.mp4\", subtitle_file)\n",
        "        new_highlighted_files = search_words_in_transcription(subtitle_file, keywords)\n",
        "\n",
        "        if not new_highlighted_files:\n",
        "            return\n",
        "\n",
        "        highlighted_sections = extract_highlighted_sections(new_highlighted_files)\n",
        "        create_highlight_video(f\"video_{storage_format}.mp4\", highlighted_sections)\n",
        "\n",
        "        # Add new keywords and highlighted sections to existing video entry\n",
        "        new_keywords = {\n",
        "            \"keyword\": keywords,\n",
        "            \"highlighted_sections\": highlighted_sections\n",
        "        }\n",
        "        existing_video_entry['details'][0]['keywords'].append(new_keywords)\n",
        "\n",
        "        # Save the updated data to file\n",
        "        if storage_format == 'json':\n",
        "            save_to_json(video_data_file, existing_videos)\n",
        "        else:\n",
        "            save_to_xml(video_data_file, existing_videos)\n",
        "\n",
        "        print(f\"Updated entry added for keywords: {keywords} with new highlighted sections.\")\n",
        "        return\n",
        "\n",
        "    # If the video URL is not found, process it as a new video\n",
        "    subtitle_file = f\"subtitle_{storage_format}.json\"\n",
        "    download_video_yt_dlp(video_url, f\"video_{storage_format}.mp4\")\n",
        "    process_video_to_audio(f\"video_{storage_format}.mp4\", subtitle_file)\n",
        "    highlighted_subtitle_files = search_words_in_transcription(subtitle_file, keywords)\n",
        "\n",
        "    if not highlighted_subtitle_files:\n",
        "        return\n",
        "\n",
        "    highlighted_sections = extract_highlighted_sections(highlighted_subtitle_files)\n",
        "    create_highlight_video(f\"video_{storage_format}.mp4\", highlighted_sections)\n",
        "\n",
        "    # Create new video entry\n",
        "    new_video = {\n",
        "        \"video_url\": video_url,\n",
        "        \"details\": [\n",
        "            {\n",
        "                \"keywords\": [\n",
        "                    {\n",
        "                        \"keyword\": keywords,\n",
        "                        \"highlighted_sections\": highlighted_sections\n",
        "                    }\n",
        "                ]\n",
        "            }\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    # Append new video entry to the existing data\n",
        "    existing_videos.append(new_video)\n",
        "\n",
        "    # Save the updated data to file\n",
        "    if storage_format == 'json':\n",
        "        save_to_json(video_data_file, existing_videos)\n",
        "    else:\n",
        "        save_to_xml(video_data_file, existing_videos)\n",
        "\n",
        "    print(f\"New entry added for video URL: {video_url}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gXuscizuDZtw"
      },
      "source": [
        "Calling the main funciton for json file storage system"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "stgVhaqJb33F"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "start_time = time.time()\n",
        "create_video_json_or_xml(storage_format='json')  # Call for JSON storage\n",
        "end_time = time.time()  # Capture the end time\n",
        "execution_time = end_time - start_time  # Calculate the total execution time\n",
        "print(f\"Total execution time: {execution_time:.2f} seconds\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0v8DHOhEEhV"
      },
      "source": [
        "Calling main funciton for the xml file storage system"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oHza5_v-b6fx"
      },
      "outputs": [],
      "source": [
        "start_time = time.time()\n",
        "create_video_json_or_xml(storage_format='xml')   # Call for XML storage\n",
        "end_time = time.time()  # Capture the end time\n",
        "execution_time = end_time - start_time  # Calculate the total execution time\n",
        "print(f\"Total execution time: {execution_time:.2f} seconds\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zssNHxdCW3_t"
      },
      "source": [
        "# Frequency of words finding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2A1FLQzWai4O",
        "outputId": "0072f3e0-665d-4c2e-b3da-81b5b67c616c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Top 10 Noun frequencies (excluding unwanted words):\n",
            "task: 20\n",
            "%: 13\n",
            "words: 11\n",
            "band: 11\n",
            "overview: 9\n",
            "time: 8\n",
            "data: 8\n",
            "charts: 7\n",
            "school: 7\n",
            "changes: 6\n",
            "\n",
            "Top 10 Noun frequencies (excluding unwanted words):\n",
            "words: 11\n",
            "charts: 7\n",
            "changes: 6\n",
            "data: 5\n",
            "maps: 4\n",
            "appliances: 4\n",
            "stages: 4\n",
            "errors: 4\n",
            "bottles: 4\n",
            "answers: 3\n",
            "\n",
            "Top 10 Noun frequencies (excluding unwanted words):\n",
            "ielts: 5\n",
            "band: 4\n",
            "cambridge: 2\n",
            "remember: 2\n",
            "time: 1\n",
            "wait: 1\n",
            "well: 1\n",
            "back: 1\n",
            "first: 1\n",
            "taster: 1\n",
            "\n",
            "Top 10 Noun frequencies (excluding unwanted words):\n",
            "\n",
            "Top 10 Adjective frequencies (excluding unwanted words):\n",
            "first: 8\n",
            "important: 6\n",
            "third: 6\n",
            "main: 5\n",
            "good: 5\n",
            "vocabulary: 5\n",
            "possible: 4\n",
            "second: 4\n",
            "new: 4\n",
            "key: 3\n",
            "\n",
            "Top 10 Adjective frequencies (excluding unwanted words):\n",
            "higher: 2\n",
            "less: 2\n",
            "better: 2\n",
            "easier: 1\n",
            "older: 1\n",
            "lower: 1\n",
            "more: 1\n",
            "\n",
            "Top 10 Adjective frequencies (excluding unwanted words):\n",
            "least: 1\n",
            "best: 1\n",
            "most: 1\n",
            "\n",
            "Top 10 Adverb frequencies (excluding unwanted words):\n",
            "also: 10\n",
            "really: 5\n",
            "together: 5\n",
            "well: 4\n",
            "only: 3\n",
            "there: 2\n",
            "notice: 2\n",
            "again: 2\n",
            "even: 2\n",
            "now: 2\n",
            "\n",
            "Top 10 Adverb frequencies (excluding unwanted words):\n",
            "longer: 1\n",
            "\n",
            "Top 10 Adverb frequencies (excluding unwanted words):\n",
            "\n",
            "Top 10 Verb frequencies (excluding unwanted words):\n",
            "show: 8\n",
            "use: 7\n",
            "let: 7\n",
            "see: 7\n",
            "write: 5\n",
            "know: 4\n",
            "learn: 4\n",
            "linked: 4\n",
            "describe: 3\n",
            "going: 3\n",
            "\n",
            "Top 10 Verb frequencies (excluding unwanted words):\n",
            "possessed: 2\n",
            "spent: 1\n",
            "grew: 1\n",
            "rose: 1\n",
            "created: 1\n",
            "happened: 1\n",
            "predicted: 1\n",
            "used: 1\n",
            "sent: 1\n",
            "touched: 1\n",
            "\n",
            "Top 10 Verb frequencies (excluding unwanted words):\n",
            "going: 3\n",
            "describing: 3\n",
            "recycling: 3\n",
            "using: 2\n",
            "looking: 2\n",
            "existing: 2\n",
            "sorting: 2\n",
            "crushing: 2\n",
            "selecting: 1\n",
            "reporting: 1\n",
            "\n",
            "Top 10 Verb frequencies (excluding unwanted words):\n",
            "linked: 4\n",
            "spent: 2\n",
            "selected: 2\n",
            "devoted: 2\n",
            "maintained: 2\n",
            "planned: 2\n",
            "shortened: 2\n",
            "constructed: 2\n",
            "relecated: 2\n",
            "required: 1\n",
            "\n",
            "Top 10 Verb frequencies (excluding unwanted words):\n",
            "see: 5\n",
            "show: 3\n",
            "want: 3\n",
            "need: 3\n",
            "know: 3\n",
            "go: 2\n",
            "provide: 2\n",
            "call: 2\n",
            "let: 2\n",
            "collocate: 2\n",
            "\n",
            "Top 10 Verb frequencies (excluding unwanted words):\n",
            "shows: 3\n",
            "presents: 2\n",
            "assesses: 1\n",
            "lists: 1\n",
            "means: 1\n",
            "says: 1\n",
            "satisfies: 1\n",
            "reveals: 1\n",
            "wants: 1\n",
            "percentages: 1\n",
            "words: 22\n",
            "task: 20\n",
            "band: 15\n",
            "charts: 14\n",
            "data: 13\n",
            "%: 13\n",
            "changes: 12\n",
            "show: 12\n",
            "first: 12\n",
            "see: 12\n"
          ]
        }
      ],
      "source": [
        "# Download required NLTK data\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "# Load JSON data from file\n",
        "with open('/content/subtitle.json', 'r') as file:\n",
        "    data = json.load(file)\n",
        "\n",
        "# Extract text from JSON\n",
        "text = ' '.join(segment['text'] for segment in data)\n",
        "\n",
        "# Tokenize and POS tagging\n",
        "tokens = word_tokenize(text)\n",
        "tagged_tokens = pos_tag(tokens)\n",
        "\n",
        "# Define POS tags for each part of speech\n",
        "POS_TAGS = {\n",
        "    'NN': 'Noun', 'NNS': 'Noun', 'NNP': 'Noun', 'NNPS': 'Noun', # Nouns\n",
        "    'JJ': 'Adjective', 'JJR': 'Adjective', 'JJS': 'Adjective',    # Adjectives\n",
        "    'RB': 'Adverb', 'RBR': 'Adverb', 'RBS': 'Adverb',             # Adverbs\n",
        "    'VB': 'Verb', 'VBD': 'Verb', 'VBG': 'Verb', 'VBN': 'Verb', 'VBP': 'Verb', 'VBZ': 'Verb'  # Verbs\n",
        "}\n",
        "\n",
        "# Define auxiliary verbs and specific adverbs to exclude\n",
        "auxiliary_verbs = set([\n",
        "    'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being',\n",
        "    'have', 'has', 'had', 'having',\n",
        "    'do', 'does', 'did', 'doing', \"'s\", \"'m\", \"'re\", \"n't\"\n",
        "])\n",
        "\n",
        "# Define adverbs to exclude\n",
        "specific_adverbs_to_exclude = set([\n",
        "    'so', \"n't\", 'just', 'right', 'not', 'here', 'maybe', 'then',  # Original adverbs\n",
        "    'often', 'always', 'never', 'rarely',  # Frequency adverbs\n",
        "    'very', 'too', 'quite',  # Intensity adverbs\n",
        "    'everywhere', 'nowhere', 'somewhere', 'anywhere',  # Place adverbs\n",
        "])\n",
        "\n",
        "# Function to filter and count words by POS tag\n",
        "def filter_words_by_pos(tagged_tokens, pos_tag_prefix):\n",
        "    return [word.lower() for word, tag in tagged_tokens if tag.startswith(pos_tag_prefix)]\n",
        "\n",
        "# Function to remove auxiliary verbs and specific adverbs\n",
        "def remove_unwanted_words(words):\n",
        "    return [word for word in words if word not in auxiliary_verbs and word not in specific_adverbs_to_exclude]\n",
        "\n",
        "# Find and print the top 10 most frequent words for each POS\n",
        "for pos_tag, pos_name in POS_TAGS.items():\n",
        "    print(f\"\\nTop 10 {pos_name} frequencies (excluding unwanted words):\")\n",
        "    filtered_words = filter_words_by_pos(tagged_tokens, pos_tag)\n",
        "    filtered_words = remove_unwanted_words(filtered_words)\n",
        "    filtered_word_freq = Counter(filtered_words)\n",
        "    most_common = filtered_word_freq.most_common(10)\n",
        "    for word, freq in most_common:\n",
        "        print(f\"{word}: {freq}\")\n",
        "\n",
        "# Aggregate filtered words from all POS tags\n",
        "all_filtered_words = []\n",
        "for pos_tag, pos_name in POS_TAGS.items():\n",
        "    filtered_words = filter_words_by_pos(tagged_tokens, pos_tag)\n",
        "    filtered_words = remove_unwanted_words(filtered_words)\n",
        "    all_filtered_words.extend(filtered_words)\n",
        "\n",
        "# Count frequencies of all filtered words\n",
        "all_word_freq = Counter(all_filtered_words)\n",
        "\n",
        "# Find and print the top 10 most frequent words overall\n",
        "most_common = all_word_freq.most_common(10)\n",
        "#print(\"\\nTop 10 most frequent words (excluding unwanted words):\")\n",
        "for word, freq in most_common:\n",
        "    print(f\"{word}: {freq}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JHE4ladasw0O",
        "outputId": "a1ae652c-dedf-4c6f-a53b-bf10655c377c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Word frequencies (excluding unwanted words):\n",
            "words: 22\n",
            "task: 20\n",
            "band: 15\n",
            "charts: 14\n",
            "data: 13\n",
            "changes: 12\n",
            "show: 12\n",
            "first: 12\n",
            "see: 12\n",
            "ielts: 10\n",
            "let: 10\n",
            "also: 10\n",
            "time: 9\n",
            "overview: 9\n",
            "stages: 9\n",
            "maps: 8\n",
            "appliances: 8\n",
            "presents: 8\n",
            "errors: 8\n",
            "bottles: 8\n",
            "recycling: 8\n",
            "use: 8\n",
            "linked: 8\n",
            "score: 7\n",
            "look: 7\n",
            "school: 7\n",
            "plastic: 7\n",
            "spent: 7\n",
            "know: 7\n",
            "answers: 6\n",
            "descriptors: 6\n",
            "requirements: 6\n",
            "sentence: 6\n",
            "devices: 6\n",
            "well: 6\n",
            "vocabulary: 6\n",
            "sentences: 6\n",
            "homes: 6\n",
            "future: 6\n",
            "sports: 6\n",
            "process: 6\n",
            "crushing: 6\n",
            "important: 6\n",
            "third: 6\n",
            "going: 6\n",
            "write: 6\n",
            "want: 6\n",
            "possessed: 6\n",
            "need: 6\n",
            "shows: 6\n",
            "describing: 6\n",
            "example: 5\n",
            "ownership: 5\n",
            "point: 5\n",
            "main: 5\n",
            "good: 5\n",
            "really: 5\n",
            "together: 5\n",
            "go: 5\n",
            "learn: 5\n",
            "examiners: 4\n",
            "cambridge: 4\n",
            "features: 4\n",
            "report: 4\n",
            "ways: 4\n",
            "question: 4\n",
            "answer: 4\n",
            "examiner: 4\n",
            "families: 4\n",
            "growth: 4\n",
            "tasks: 4\n",
            "remember: 4\n",
            "synonyms: 4\n",
            "years: 4\n",
            "quarters: 4\n",
            "courses: 4\n",
            "structures: 4\n",
            "buildings: 4\n",
            "steps: 4\n",
            "pellets: 4\n",
            "key: 4\n",
            "higher: 4\n",
            "possible: 4\n",
            "less: 4\n",
            "second: 4\n",
            "new: 4\n",
            "better: 4\n",
            "selected: 4\n",
            "provide: 4\n",
            "devoted: 4\n",
            "using: 4\n",
            "call: 4\n",
            "maintained: 4\n",
            "collocate: 4\n",
            "looking: 4\n",
            "planned: 4\n",
            "predicted: 4\n",
            "shortened: 4\n",
            "existing: 4\n",
            "constructed: 4\n",
            "relecated: 4\n",
            "sent: 4\n",
            "sorting: 4\n",
            "diagrams: 3\n",
            "writing: 3\n",
            "today: 3\n",
            "type: 3\n",
            "households: 3\n",
            "information: 3\n",
            "achievement: 3\n",
            "home: 3\n",
            "range: 3\n",
            "year: 3\n",
            "peak: 3\n",
            "back: 3\n",
            "fall: 3\n",
            "lot: 3\n",
            "rise: 3\n",
            "change: 3\n",
            "site: 3\n",
            "field: 3\n",
            "car: 3\n",
            "park: 3\n",
            "diagram: 3\n",
            "high: 3\n",
            "clear: 3\n",
            "such: 3\n",
            "washing: 3\n",
            "notice: 3\n",
            "only: 3\n",
            "describe: 3\n",
            "get: 3\n",
            "make: 3\n",
            "find: 3\n",
            "tables: 2\n",
            "criteria: 2\n",
            "amount: 2\n",
            "country: 2\n",
            "comparisons: 2\n",
            "varies: 2\n",
            "idea: 2\n",
            "elements: 2\n",
            "part: 2\n",
            "criterion: 2\n",
            "bands: 2\n",
            "word: 2\n",
            "trends: 2\n",
            "differences: 2\n",
            "tells: 2\n",
            "takers: 2\n",
            "percentage: 2\n",
            "chores: 2\n",
            "things: 2\n",
            "resource: 2\n",
            "verb: 2\n",
            "figures: 2\n",
            "wait: 2\n",
            "paragraph: 2\n",
            "details: 2\n",
            "meanings: 2\n",
            "context: 2\n",
            "inaccuracies: 2\n",
            "course: 2\n",
            "refrigerators: 2\n",
            "periods: 2\n",
            "cleaners: 2\n",
            "onwards: 2\n",
            "increases: 2\n",
            "decreases: 2\n",
            "verbs: 2\n",
            "adverbs: 2\n",
            "nouns: 2\n",
            "fractions: 2\n",
            "people: 2\n",
            "thirds: 2\n",
            "examples: 2\n",
            "exam: 2\n",
            "grammar: 2\n",
            "plans: 2\n",
            "events: 2\n",
            "numbers: 2\n",
            "entrance: 2\n",
            "road: 2\n",
            "side: 2\n",
            "workflows: 2\n",
            "something: 2\n",
            "items: 2\n",
            "pants: 2\n",
            "bags: 2\n",
            "containers: 2\n",
            "terms: 2\n",
            "bins: 2\n",
            "centers: 2\n",
            "stage: 2\n",
            "blocks: 2\n",
            "machines: 2\n",
            "pieces: 2\n",
            "opinion: 2\n",
            "place: 2\n",
            "depends: 2\n",
            "preparation: 2\n",
            "types: 2\n",
            "step: 2\n",
            "taster: 2\n",
            "slides: 2\n",
            "easier: 2\n",
            "electrical: 2\n",
            "least: 2\n",
            "essential: 2\n",
            "older: 2\n",
            "lower: 2\n",
            "more: 2\n",
            "labor-saving: 2\n",
            "domestic: 2\n",
            "lexical: 2\n",
            "precise: 2\n",
            "uncommon: 2\n",
            "accurate: 2\n",
            "best: 2\n",
            "slight: 2\n",
            "steady: 2\n",
            "vary: 2\n",
            "most: 2\n",
            "complex: 2\n",
            "much: 2\n",
            "different: 2\n",
            "south: 2\n",
            "passive: 2\n",
            "necessary: 2\n",
            "in-depth: 2\n",
            "there: 2\n",
            "assess: 2\n",
            "again: 2\n",
            "longer: 2\n",
            "even: 2\n",
            "now: 2\n",
            "dramatically: 2\n",
            "steadily: 2\n",
            "however: 2\n",
            "gradually: 2\n",
            "already: 2\n",
            "simply: 2\n",
            "required: 2\n",
            "started: 2\n",
            "take: 2\n",
            "samarized: 2\n",
            "selecting: 2\n",
            "reporting: 2\n",
            "assesses: 2\n",
            "summarizing: 2\n",
            "presented: 2\n",
            "lists: 2\n",
            "means: 2\n",
            "says: 2\n",
            "satisfies: 2\n",
            "detailed: 2\n",
            "jump: 2\n",
            "give: 2\n",
            "'ve: 2\n",
            "learned: 2\n",
            "paraphrasing: 2\n",
            "reveals: 2\n",
            "read: 2\n",
            "stand: 2\n",
            "achieve: 2\n",
            "wants: 2\n",
            "help: 2\n",
            "tolerated: 2\n",
            "possessing: 2\n",
            "grew: 2\n",
            "introduced: 2\n",
            "climbing: 2\n",
            "reached: 2\n",
            "found: 2\n",
            "risen: 2\n",
            "rose: 2\n",
            "suffering: 2\n",
            "affected: 2\n",
            "percentages: 2\n",
            "requires: 2\n",
            "created: 2\n",
            "learning: 2\n",
            "helps: 2\n",
            "think: 2\n",
            "include: 2\n",
            "interesting: 2\n",
            "illustrate: 2\n",
            "happened: 2\n",
            "written: 2\n",
            "joins: 2\n",
            "allowing: 2\n",
            "stands: 2\n",
            "teaching: 2\n",
            "connecting: 2\n",
            "pass: 2\n",
            "emphasizing: 2\n",
            "made: 2\n",
            "organized: 2\n",
            "cahesy: 2\n",
            "illustrates: 2\n",
            "used: 2\n",
            "remanufactured: 2\n",
            "recycled: 2\n",
            "involved: 2\n",
            "placed: 2\n",
            "collected: 2\n",
            "covers: 2\n",
            "leads: 2\n",
            "compressed: 2\n",
            "converted: 2\n",
            "explains: 2\n",
            "turned: 2\n",
            "connects: 2\n",
            "happens: 2\n",
            "washed: 2\n",
            "noticed: 2\n",
            "revealing: 2\n",
            "study: 2\n",
            "extended: 2\n",
            "touched: 2\n",
            "watching: 2\n",
            "pie: 1\n",
            "line: 1\n",
            "graphs: 1\n",
            "bar: 1\n",
            "sample: 1\n",
            "housework: 1\n",
            "relevant: 1\n",
            "ability: 1\n",
            "number: 1\n",
            "factor: 1\n",
            "document: 1\n",
            "bit: 1\n",
            "mystery: 1\n",
            "test: 1\n",
            "attempt: 1\n",
            "thing: 1\n",
            "connection: 1\n",
            "cooking: 1\n",
            "cleaning: 1\n",
            "version: 1\n",
            "period: 1\n",
            "relationship: 1\n",
            "decreasing: 1\n",
            "everything: 1\n",
            "mind: 1\n",
            "descriptor: 1\n",
            "lookout: 1\n",
            "aspect: 1\n",
            "way: 1\n",
            "collocation: 1\n",
            "mess: 1\n",
            "spelling: 1\n",
            "formation: 1\n",
            "extent: 1\n",
            "try: 1\n",
            "depth: 1\n",
            "chart: 1\n",
            "figure: 1\n",
            "remainder: 1\n",
            "aid: 1\n",
            "machine: 1\n",
            "appliance: 1\n",
            "grow: 1\n",
            "climb: 1\n",
            "maintain: 1\n",
            "quarter: 1\n",
            "day: 1\n",
            "topic: 1\n",
            "language: 1\n",
            "ranger: 1\n",
            "control: 1\n",
            "punctuation: 1\n",
            "showing: 1\n",
            "past: 1\n",
            "plan: 1\n",
            "student: 1\n",
            "increase: 1\n",
            "path: 1\n",
            "building: 1\n",
            "area: 1\n",
            "simple: 1\n",
            "voice: 1\n",
            "cahherence: 1\n",
            "structure: 1\n",
            "paragraphs: 1\n",
            "transition: 1\n",
            "issue: 1\n",
            "purpose: 1\n",
            "series: 1\n",
            "brand: 1\n",
            "turn: 1\n",
            "consequence: 1\n",
            "beginning: 1\n",
            "reason: 1\n",
            "one: 1\n",
            "making: 1\n",
            "conclusion: 1\n",
            "start: 1\n",
            "insider: 1\n",
            "knowledge: 1\n",
            "space: 1\n",
            "online: 1\n",
            "description: 1\n",
            "lesson: 1\n",
            "introduction: 1\n",
            "preview: 1\n",
            "video: 1\n",
            "luck: 1\n",
            "academic: 1\n",
            "wrong: 1\n",
            "fast: 1\n",
            "little: 1\n",
            "obvious: 1\n",
            "unnamed: 1\n",
            "average: 1\n",
            "100-year: 1\n",
            "become: 1\n",
            "general: 1\n",
            "raw: 1\n",
            "graphic: 1\n",
            "appropriate: 1\n",
            "usual: 1\n",
            "common: 1\n",
            "wide: 1\n",
            "deep: 1\n",
            "natural: 1\n",
            "following: 1\n",
            "fourth: 1\n",
            "half: 1\n",
            "specific: 1\n",
            "noticing: 1\n",
            "error-free: 1\n",
            "minor: 1\n",
            "major: 1\n",
            "other: 1\n",
            "several: 1\n",
            "present: 1\n",
            "final: 1\n",
            "cahesian: 1\n",
            "cahherent: 1\n",
            "smooth: 1\n",
            "next: 1\n",
            "overall: 1\n",
            "sequential: 1\n",
            "specified: 1\n",
            "suitable: 1\n",
            "large: 1\n",
            "small: 1\n",
            "crushed: 1\n",
            "previous: 1\n",
            "extra: 1\n",
            "free: 1\n",
            "paid: 1\n",
            "absolutely: 1\n",
            "sometimes: 1\n",
            "fully: 1\n",
            "appropriately: 1\n",
            "mechanically: 1\n",
            "fairly: 1\n",
            "weekly: 1\n",
            "yes: 1\n",
            "no: 1\n",
            "secondly: 1\n",
            "yet: 1\n",
            "essentially: 1\n",
            "perfectly: 1\n",
            "up: 1\n",
            "down: 1\n",
            "instead: 1\n",
            "similarly: 1\n",
            "definitely: 1\n",
            "as: 1\n",
            "pretty: 1\n",
            "clearly: 1\n",
            "still: 1\n",
            "additionally: 1\n",
            "currently: 1\n",
            "meanwhile: 1\n",
            "directly: 1\n",
            "along: 1\n",
            "logically: 1\n",
            "perhaps: 1\n",
            "eventually: 1\n",
            "likely: 1\n",
            "subsequently: 1\n",
            "sufficiently: 1\n",
            "later: 1\n",
            "thoroughly: 1\n",
            "once: 1\n",
            "discuss: 1\n",
            "ask: 1\n",
            "interpret: 1\n",
            "household: 1\n",
            "summarize: 1\n",
            "paraphrase: 1\n",
            "keep: 1\n",
            "understood: 1\n",
            "move: 1\n",
            "express: 1\n",
            "combine: 1\n",
            "inaccurate: 1\n",
            "obtain: 1\n",
            "offer: 1\n",
            "reach: 1\n",
            "compare: 1\n",
            "accommodate: 1\n",
            "talk: 1\n",
            "produce: 1\n",
            "understand: 1\n",
            "say: 1\n",
            "meet: 1\n",
            "analyze: 1\n",
            "select: 1\n",
            "address: 1\n",
            "prepare: 1\n",
            "link: 1\n",
            "like: 1\n",
            "watch: 1\n",
            "forget: 1\n",
            "download: 1\n",
            "thank: 1\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from collections import Counter\n",
        "\n",
        "# Download required NLTK data\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "# Load JSON data from file\n",
        "with open('/content/subtitle_json.json', 'r') as file:\n",
        "    data = json.load(file)\n",
        "\n",
        "# Extract text from JSON\n",
        "text = ' '.join(segment['text'] for segment in data)\n",
        "\n",
        "# Tokenize and POS tagging\n",
        "tokens = word_tokenize(text)\n",
        "tagged_tokens = pos_tag(tokens)\n",
        "\n",
        "# Define POS tags for nouns, adjectives, adverbs, and verbs\n",
        "POS_TAGS = {\n",
        "    'NN': 'Noun', 'NNS': 'Noun', 'NNP': 'Noun', 'NNPS': 'Noun',  # Nouns\n",
        "    'JJ': 'Adjective', 'JJR': 'Adjective', 'JJS': 'Adjective',   # Adjectives\n",
        "    'RB': 'Adverb', 'RBR': 'Adverb', 'RBS': 'Adverb',            # Adverbs\n",
        "    'VB': 'Verb', 'VBD': 'Verb', 'VBG': 'Verb', 'VBN': 'Verb', 'VBP': 'Verb', 'VBZ': 'Verb'  # Verbs\n",
        "}\n",
        "\n",
        "# Define auxiliary verbs and specific adverbs to exclude\n",
        "auxiliary_verbs = set([\n",
        "    'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being',\n",
        "    'have', 'has', 'had', 'having',\n",
        "    'do', 'does', 'did', 'doing', \"'s\", \"'m\", \"'re\", \"n't\"\n",
        "])\n",
        "\n",
        "# Define adverbs to exclude\n",
        "specific_adverbs_to_exclude = set([\n",
        "    'so', \"n't\", 'just', 'right', 'not', 'here', 'maybe', 'then',  # Original adverbs\n",
        "    'often', 'always', 'never', 'rarely',  # Frequency adverbs\n",
        "    'very', 'too', 'quite',  # Intensity adverbs\n",
        "    'everywhere', 'nowhere', 'somewhere', 'anywhere','%',  # Place adverbs\n",
        "])\n",
        "\n",
        "# Function to filter and count words by POS tag\n",
        "def filter_words_by_pos(tagged_tokens, pos_tag_prefix):\n",
        "    return [word.lower() for word, tag in tagged_tokens if tag.startswith(pos_tag_prefix)]\n",
        "\n",
        "# Function to remove auxiliary verbs and specific adverbs\n",
        "def remove_unwanted_words(words):\n",
        "    return [word for word in words if word not in auxiliary_verbs and word not in specific_adverbs_to_exclude]\n",
        "\n",
        "# Filter by nouns, adjectives, verbs, and adverbs\n",
        "filtered_words = []\n",
        "for pos_tag, pos_name in POS_TAGS.items():\n",
        "    filtered_pos_words = filter_words_by_pos(tagged_tokens, pos_tag)\n",
        "    filtered_pos_words = remove_unwanted_words(filtered_pos_words)\n",
        "    filtered_words.extend(filtered_pos_words)\n",
        "\n",
        "# Count frequencies of all filtered words\n",
        "all_word_freq = Counter(filtered_words)\n",
        "\n",
        "# Sort and print all words by frequency (no limit)\n",
        "print(\"\\nWord frequencies (excluding unwanted words):\")\n",
        "for word, freq in all_word_freq.most_common():\n",
        "    print(f\"{word}: {freq}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fTjJE3a8H8c0",
        "outputId": "50245c7d-55f4-49bc-d6f4-147c45fe843a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Noun frequencies (excluding unwanted words):\n",
            "task: 20\n",
            "%: 13\n",
            "words: 11\n",
            "band: 11\n",
            "overview: 9\n",
            "time: 8\n",
            "data: 8\n",
            "charts: 7\n",
            "school: 7\n",
            "changes: 6\n",
            "score: 6\n",
            "sentence: 6\n",
            "process: 6\n",
            "ielts: 5\n",
            "example: 5\n",
            "ownership: 5\n",
            "look: 5\n",
            "plastic: 5\n",
            "maps: 4\n",
            "appliances: 4\n",
            "report: 4\n",
            "question: 4\n",
            "answer: 4\n",
            "examiner: 4\n",
            "stages: 4\n",
            "growth: 4\n",
            "synonyms: 4\n",
            "errors: 4\n",
            "bottles: 4\n",
            "today: 3\n",
            "answers: 3\n",
            "type: 3\n",
            "information: 3\n",
            "achievement: 3\n",
            "descriptors: 3\n",
            "requirements: 3\n",
            "home: 3\n",
            "devices: 3\n",
            "point: 3\n",
            "range: 3\n",
            "sentences: 3\n",
            "homes: 3\n",
            "year: 3\n",
            "peak: 3\n",
            "fall: 3\n",
            "lot: 3\n",
            "future: 3\n",
            "site: 3\n",
            "sports: 3\n",
            "field: 3\n",
            "car: 3\n",
            "park: 3\n",
            "diagram: 3\n",
            "diagrams: 2\n",
            "criteria: 2\n",
            "examiners: 2\n",
            "cambridge: 2\n",
            "amount: 2\n",
            "country: 2\n",
            "features: 2\n",
            "ways: 2\n",
            "idea: 2\n",
            "part: 2\n",
            "criterion: 2\n",
            "word: 2\n",
            "presents: 2\n",
            "percentage: 2\n",
            "families: 2\n",
            "tasks: 2\n",
            "remember: 2\n",
            "resource: 2\n",
            "so: 2\n",
            "verb: 2\n",
            "paragraph: 2\n",
            "right: 2\n",
            "context: 2\n",
            "course: 2\n",
            "years: 2\n",
            "quarters: 2\n",
            "change: 2\n",
            "courses: 2\n",
            "exam: 2\n",
            "grammar: 2\n",
            "structures: 2\n",
            "entrance: 2\n",
            "buildings: 2\n",
            "road: 2\n",
            "side: 2\n",
            "something: 2\n",
            "recycling: 2\n",
            "steps: 2\n",
            "stage: 2\n",
            "crushing: 2\n",
            "pellets: 2\n",
            "opinion: 2\n",
            "place: 2\n",
            "preparation: 2\n",
            "step: 2\n",
            "pie: 1\n",
            "line: 1\n",
            "graphs: 1\n",
            "bar: 1\n",
            "tables: 1\n",
            "writing: 1\n",
            "sample: 1\n",
            "housework: 1\n",
            "households: 1\n",
            "comparisons: 1\n",
            "relevant: 1\n",
            "ability: 1\n",
            "number: 1\n",
            "varies: 1\n",
            "elements: 1\n",
            "factor: 1\n",
            "document: 1\n",
            "bit: 1\n",
            "mystery: 1\n",
            "bands: 1\n",
            "trends: 1\n",
            "differences: 1\n",
            "tells: 1\n",
            "test: 1\n",
            "takers: 1\n",
            "attempt: 1\n",
            "thing: 1\n",
            "connection: 1\n",
            "cooking: 1\n",
            "cleaning: 1\n",
            "version: 1\n",
            "chores: 1\n",
            "period: 1\n",
            "relationship: 1\n",
            "decreasing: 1\n",
            "things: 1\n",
            "everything: 1\n",
            "figures: 1\n",
            "mind: 1\n",
            "wait: 1\n",
            "details: 1\n",
            "descriptor: 1\n",
            "meanings: 1\n",
            "lookout: 1\n",
            "aspect: 1\n",
            "way: 1\n",
            "collocation: 1\n",
            "mess: 1\n",
            "well: 1\n",
            "spelling: 1\n",
            "formation: 1\n",
            "extent: 1\n",
            "inaccuracies: 1\n",
            "vocabulary: 1\n",
            "try: 1\n",
            "depth: 1\n",
            "chart: 1\n",
            "refrigerators: 1\n",
            "figure: 1\n",
            "remainder: 1\n",
            "periods: 1\n",
            "aid: 1\n",
            "back: 1\n",
            "cleaners: 1\n",
            "onwards: 1\n",
            "machine: 1\n",
            "appliance: 1\n",
            "increases: 1\n",
            "decreases: 1\n",
            "verbs: 1\n",
            "grow: 1\n",
            "climb: 1\n",
            "rise: 1\n",
            "adverbs: 1\n",
            "nouns: 1\n",
            "maintain: 1\n",
            "fractions: 1\n",
            "quarter: 1\n",
            "people: 1\n",
            "thirds: 1\n",
            "day: 1\n",
            "examples: 1\n",
            "topic: 1\n",
            "language: 1\n",
            "ranger: 1\n",
            "control: 1\n",
            "punctuation: 1\n",
            "let: 1\n",
            "showing: 1\n",
            "plans: 1\n",
            "past: 1\n",
            "show: 1\n",
            "plan: 1\n",
            "events: 1\n",
            "student: 1\n",
            "numbers: 1\n",
            "increase: 1\n",
            "path: 1\n",
            "building: 1\n",
            "area: 1\n",
            "workflows: 1\n",
            "simple: 1\n",
            "voice: 1\n",
            "cahherence: 1\n",
            "structure: 1\n",
            "paragraphs: 1\n",
            "transition: 1\n",
            "issue: 1\n",
            "purpose: 1\n",
            "series: 1\n",
            "brand: 1\n",
            "items: 1\n",
            "pants: 1\n",
            "bags: 1\n",
            "containers: 1\n",
            "turn: 1\n",
            "terms: 1\n",
            "consequence: 1\n",
            "first: 1\n",
            "bins: 1\n",
            "centers: 1\n",
            "beginning: 1\n",
            "reason: 1\n",
            "blocks: 1\n",
            "machines: 1\n",
            "pieces: 1\n",
            "one: 1\n",
            "making: 1\n",
            "conclusion: 1\n",
            "start: 1\n",
            "insider: 1\n",
            "knowledge: 1\n",
            "space: 1\n",
            "depends: 1\n",
            "key: 1\n",
            "types: 1\n",
            "online: 1\n",
            "description: 1\n",
            "taster: 1\n",
            "lesson: 1\n",
            "introduction: 1\n",
            "preview: 1\n",
            "slides: 1\n",
            "video: 1\n",
            "luck: 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from collections import Counter\n",
        "\n",
        "# Download required NLTK data\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "# Load JSON data from file\n",
        "with open('/content/subtitle.json', 'r') as file:\n",
        "    data = json.load(file)\n",
        "\n",
        "# Extract text from JSON\n",
        "text = ' '.join(segment['text'] for segment in data)\n",
        "\n",
        "# Tokenize and POS tagging\n",
        "tokens = word_tokenize(text)\n",
        "tagged_tokens = pos_tag(tokens)\n",
        "\n",
        "# Define POS tags for nouns only\n",
        "NOUN_TAGS = {\n",
        "    'NN': 'Noun', 'NNS': 'Noun', 'NNP': 'Proper Noun', 'NNPS': 'Proper Noun'  # Nouns and Proper Nouns\n",
        "}\n",
        "\n",
        "# Function to filter nouns\n",
        "def filter_nouns(tagged_tokens):\n",
        "    return [word.lower() for word, tag in tagged_tokens if tag in NOUN_TAGS]\n",
        "\n",
        "# Extract and filter only nouns\n",
        "filtered_nouns = filter_nouns(tagged_tokens)\n",
        "\n",
        "# Count frequencies of all filtered nouns\n",
        "noun_freq = Counter(filtered_nouns)\n",
        "\n",
        "# Sort and print all nouns by frequency (no limit)\n",
        "print(\"\\nNoun frequencies (excluding unwanted words):\")\n",
        "for word, freq in noun_freq.most_common():\n",
        "    print(f\"{word}: {freq}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "v5m6T7N9ruMO",
        "outputId": "1d353e40-37f6-478c-fbef-fcb1c50790db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "words: 22\n",
            "task: 20\n",
            "band: 15\n",
            "charts: 14\n",
            "data: 13\n",
            "%: 13\n",
            "changes: 12\n",
            "show: 12\n",
            "first: 12\n",
            "see: 12\n",
            "ielts: 10\n",
            "let: 10\n",
            "also: 10\n",
            "time: 9\n",
            "overview: 9\n",
            "stages: 9\n",
            "maps: 8\n",
            "appliances: 8\n",
            "presents: 8\n",
            "errors: 8\n",
            "bottles: 8\n",
            "recycling: 8\n",
            "use: 8\n",
            "linked: 8\n",
            "score: 7\n",
            "look: 7\n",
            "school: 7\n",
            "plastic: 7\n",
            "spent: 7\n",
            "know: 7\n",
            "answers: 6\n",
            "descriptors: 6\n",
            "requirements: 6\n",
            "sentence: 6\n",
            "devices: 6\n",
            "well: 6\n",
            "vocabulary: 6\n",
            "sentences: 6\n",
            "homes: 6\n",
            "future: 6\n",
            "sports: 6\n",
            "process: 6\n",
            "crushing: 6\n",
            "important: 6\n",
            "third: 6\n",
            "going: 6\n",
            "write: 6\n",
            "want: 6\n",
            "possessed: 6\n",
            "need: 6\n",
            "shows: 6\n",
            "describing: 6\n",
            "example: 5\n",
            "ownership: 5\n",
            "point: 5\n",
            "main: 5\n",
            "good: 5\n",
            "really: 5\n",
            "together: 5\n",
            "go: 5\n",
            "learn: 5\n",
            "examiners: 4\n",
            "cambridge: 4\n",
            "features: 4\n",
            "report: 4\n",
            "ways: 4\n",
            "question: 4\n",
            "answer: 4\n",
            "examiner: 4\n",
            "families: 4\n",
            "growth: 4\n",
            "tasks: 4\n",
            "remember: 4\n",
            "synonyms: 4\n",
            "years: 4\n",
            "quarters: 4\n",
            "courses: 4\n",
            "structures: 4\n",
            "buildings: 4\n",
            "steps: 4\n",
            "pellets: 4\n",
            "key: 4\n",
            "higher: 4\n",
            "possible: 4\n",
            "less: 4\n",
            "second: 4\n",
            "new: 4\n",
            "better: 4\n",
            "selected: 4\n",
            "provide: 4\n",
            "devoted: 4\n",
            "using: 4\n",
            "call: 4\n",
            "maintained: 4\n",
            "collocate: 4\n",
            "looking: 4\n",
            "planned: 4\n",
            "predicted: 4\n",
            "shortened: 4\n",
            "existing: 4\n",
            "constructed: 4\n",
            "relecated: 4\n",
            "sent: 4\n",
            "sorting: 4\n",
            "diagrams: 3\n",
            "writing: 3\n",
            "today: 3\n",
            "type: 3\n",
            "households: 3\n",
            "information: 3\n",
            "achievement: 3\n",
            "home: 3\n",
            "range: 3\n",
            "year: 3\n",
            "peak: 3\n",
            "back: 3\n",
            "fall: 3\n",
            "lot: 3\n",
            "rise: 3\n",
            "change: 3\n",
            "site: 3\n",
            "field: 3\n",
            "car: 3\n",
            "park: 3\n",
            "diagram: 3\n",
            "high: 3\n",
            "clear: 3\n",
            "such: 3\n",
            "washing: 3\n",
            "notice: 3\n",
            "only: 3\n",
            "describe: 3\n",
            "get: 3\n",
            "make: 3\n",
            "find: 3\n",
            "tables: 2\n",
            "criteria: 2\n",
            "amount: 2\n",
            "country: 2\n",
            "comparisons: 2\n",
            "varies: 2\n",
            "idea: 2\n",
            "elements: 2\n",
            "part: 2\n",
            "criterion: 2\n",
            "bands: 2\n",
            "word: 2\n",
            "trends: 2\n",
            "differences: 2\n",
            "tells: 2\n",
            "takers: 2\n",
            "percentage: 2\n",
            "chores: 2\n",
            "things: 2\n",
            "resource: 2\n",
            "verb: 2\n",
            "figures: 2\n",
            "wait: 2\n",
            "paragraph: 2\n",
            "details: 2\n",
            "meanings: 2\n",
            "context: 2\n",
            "inaccuracies: 2\n",
            "course: 2\n",
            "refrigerators: 2\n",
            "periods: 2\n",
            "cleaners: 2\n",
            "onwards: 2\n",
            "increases: 2\n",
            "decreases: 2\n",
            "verbs: 2\n",
            "adverbs: 2\n",
            "nouns: 2\n",
            "fractions: 2\n",
            "people: 2\n",
            "thirds: 2\n",
            "examples: 2\n",
            "exam: 2\n",
            "grammar: 2\n",
            "plans: 2\n",
            "events: 2\n",
            "numbers: 2\n",
            "entrance: 2\n",
            "road: 2\n",
            "side: 2\n",
            "workflows: 2\n",
            "something: 2\n",
            "items: 2\n",
            "pants: 2\n",
            "bags: 2\n",
            "containers: 2\n",
            "terms: 2\n",
            "bins: 2\n",
            "centers: 2\n",
            "stage: 2\n",
            "blocks: 2\n",
            "machines: 2\n",
            "pieces: 2\n",
            "opinion: 2\n",
            "place: 2\n",
            "depends: 2\n",
            "preparation: 2\n",
            "types: 2\n",
            "step: 2\n",
            "taster: 2\n",
            "slides: 2\n",
            "easier: 2\n",
            "electrical: 2\n",
            "least: 2\n",
            "essential: 2\n",
            "older: 2\n",
            "lower: 2\n",
            "more: 2\n",
            "labor-saving: 2\n",
            "domestic: 2\n",
            "lexical: 2\n",
            "precise: 2\n",
            "uncommon: 2\n",
            "accurate: 2\n",
            "best: 2\n",
            "slight: 2\n",
            "steady: 2\n",
            "vary: 2\n",
            "most: 2\n",
            "complex: 2\n",
            "much: 2\n",
            "different: 2\n",
            "south: 2\n",
            "passive: 2\n",
            "necessary: 2\n",
            "in-depth: 2\n",
            "there: 2\n",
            "assess: 2\n",
            "again: 2\n",
            "longer: 2\n",
            "even: 2\n",
            "now: 2\n",
            "dramatically: 2\n",
            "steadily: 2\n",
            "however: 2\n",
            "gradually: 2\n",
            "already: 2\n",
            "simply: 2\n",
            "required: 2\n",
            "started: 2\n",
            "take: 2\n",
            "samarized: 2\n",
            "selecting: 2\n",
            "reporting: 2\n",
            "assesses: 2\n",
            "summarizing: 2\n",
            "presented: 2\n",
            "lists: 2\n",
            "means: 2\n",
            "says: 2\n",
            "satisfies: 2\n",
            "detailed: 2\n",
            "jump: 2\n",
            "give: 2\n",
            "'ve: 2\n",
            "learned: 2\n",
            "paraphrasing: 2\n",
            "reveals: 2\n",
            "read: 2\n",
            "stand: 2\n",
            "achieve: 2\n",
            "wants: 2\n",
            "help: 2\n",
            "tolerated: 2\n",
            "possessing: 2\n",
            "grew: 2\n",
            "introduced: 2\n",
            "climbing: 2\n",
            "reached: 2\n",
            "found: 2\n",
            "risen: 2\n",
            "rose: 2\n",
            "suffering: 2\n",
            "affected: 2\n",
            "percentages: 2\n",
            "requires: 2\n",
            "created: 2\n",
            "learning: 2\n",
            "helps: 2\n",
            "think: 2\n",
            "include: 2\n",
            "interesting: 2\n",
            "illustrate: 2\n",
            "happened: 2\n",
            "written: 2\n",
            "joins: 2\n",
            "allowing: 2\n",
            "stands: 2\n",
            "teaching: 2\n",
            "connecting: 2\n",
            "pass: 2\n",
            "emphasizing: 2\n",
            "made: 2\n",
            "organized: 2\n",
            "cahesy: 2\n",
            "illustrates: 2\n",
            "used: 2\n",
            "remanufactured: 2\n",
            "recycled: 2\n",
            "involved: 2\n",
            "placed: 2\n",
            "collected: 2\n",
            "covers: 2\n",
            "leads: 2\n",
            "compressed: 2\n",
            "converted: 2\n",
            "explains: 2\n",
            "turned: 2\n",
            "connects: 2\n",
            "happens: 2\n",
            "washed: 2\n",
            "noticed: 2\n",
            "revealing: 2\n",
            "study: 2\n",
            "extended: 2\n",
            "touched: 2\n",
            "watching: 2\n",
            "pie: 1\n",
            "line: 1\n",
            "graphs: 1\n",
            "bar: 1\n",
            "sample: 1\n",
            "housework: 1\n",
            "relevant: 1\n",
            "ability: 1\n",
            "number: 1\n",
            "factor: 1\n",
            "document: 1\n",
            "bit: 1\n",
            "mystery: 1\n",
            "test: 1\n",
            "attempt: 1\n",
            "thing: 1\n",
            "connection: 1\n",
            "cooking: 1\n",
            "cleaning: 1\n",
            "version: 1\n",
            "period: 1\n",
            "relationship: 1\n",
            "decreasing: 1\n",
            "everything: 1\n",
            "mind: 1\n",
            "descriptor: 1\n",
            "lookout: 1\n",
            "aspect: 1\n",
            "way: 1\n",
            "collocation: 1\n",
            "mess: 1\n",
            "spelling: 1\n",
            "formation: 1\n",
            "extent: 1\n",
            "try: 1\n",
            "depth: 1\n",
            "chart: 1\n",
            "figure: 1\n",
            "remainder: 1\n",
            "aid: 1\n",
            "machine: 1\n",
            "appliance: 1\n",
            "grow: 1\n",
            "climb: 1\n",
            "maintain: 1\n",
            "quarter: 1\n",
            "day: 1\n",
            "topic: 1\n",
            "language: 1\n",
            "ranger: 1\n",
            "control: 1\n",
            "punctuation: 1\n",
            "showing: 1\n",
            "past: 1\n",
            "plan: 1\n",
            "student: 1\n",
            "increase: 1\n",
            "path: 1\n",
            "building: 1\n",
            "area: 1\n",
            "simple: 1\n",
            "voice: 1\n",
            "cahherence: 1\n",
            "structure: 1\n",
            "paragraphs: 1\n",
            "transition: 1\n",
            "issue: 1\n",
            "purpose: 1\n",
            "series: 1\n",
            "brand: 1\n",
            "turn: 1\n",
            "consequence: 1\n",
            "beginning: 1\n",
            "reason: 1\n",
            "one: 1\n",
            "making: 1\n",
            "conclusion: 1\n",
            "start: 1\n",
            "insider: 1\n",
            "knowledge: 1\n",
            "space: 1\n",
            "online: 1\n",
            "description: 1\n",
            "lesson: 1\n",
            "introduction: 1\n",
            "preview: 1\n",
            "video: 1\n",
            "luck: 1\n",
            "academic: 1\n",
            "wrong: 1\n",
            "fast: 1\n",
            "little: 1\n",
            "obvious: 1\n",
            "unnamed: 1\n",
            "average: 1\n",
            "100-year: 1\n",
            "become: 1\n",
            "general: 1\n",
            "raw: 1\n",
            "graphic: 1\n",
            "appropriate: 1\n",
            "usual: 1\n",
            "common: 1\n",
            "wide: 1\n",
            "deep: 1\n",
            "natural: 1\n",
            "following: 1\n",
            "fourth: 1\n",
            "half: 1\n",
            "specific: 1\n",
            "noticing: 1\n",
            "error-free: 1\n",
            "minor: 1\n",
            "major: 1\n",
            "other: 1\n",
            "several: 1\n",
            "present: 1\n",
            "final: 1\n",
            "cahesian: 1\n",
            "cahherent: 1\n",
            "smooth: 1\n",
            "next: 1\n",
            "overall: 1\n",
            "sequential: 1\n",
            "specified: 1\n",
            "suitable: 1\n",
            "large: 1\n",
            "small: 1\n",
            "crushed: 1\n",
            "previous: 1\n",
            "extra: 1\n",
            "free: 1\n",
            "paid: 1\n",
            "absolutely: 1\n",
            "sometimes: 1\n",
            "fully: 1\n",
            "appropriately: 1\n",
            "mechanically: 1\n",
            "fairly: 1\n",
            "weekly: 1\n",
            "yes: 1\n",
            "no: 1\n",
            "secondly: 1\n",
            "yet: 1\n",
            "essentially: 1\n",
            "perfectly: 1\n",
            "up: 1\n",
            "down: 1\n",
            "instead: 1\n",
            "similarly: 1\n",
            "definitely: 1\n",
            "as: 1\n",
            "pretty: 1\n",
            "clearly: 1\n",
            "still: 1\n",
            "additionally: 1\n",
            "currently: 1\n",
            "meanwhile: 1\n",
            "directly: 1\n",
            "along: 1\n",
            "logically: 1\n",
            "perhaps: 1\n",
            "eventually: 1\n",
            "likely: 1\n",
            "subsequently: 1\n",
            "sufficiently: 1\n",
            "later: 1\n",
            "thoroughly: 1\n",
            "once: 1\n",
            "discuss: 1\n",
            "ask: 1\n",
            "interpret: 1\n",
            "household: 1\n",
            "summarize: 1\n",
            "paraphrase: 1\n",
            "keep: 1\n",
            "understood: 1\n",
            "move: 1\n",
            "express: 1\n",
            "combine: 1\n",
            "inaccurate: 1\n",
            "obtain: 1\n",
            "offer: 1\n",
            "reach: 1\n",
            "compare: 1\n",
            "accommodate: 1\n",
            "talk: 1\n",
            "produce: 1\n",
            "understand: 1\n",
            "say: 1\n",
            "meet: 1\n",
            "analyze: 1\n",
            "select: 1\n",
            "address: 1\n",
            "prepare: 1\n",
            "link: 1\n",
            "like: 1\n",
            "watch: 1\n",
            "forget: 1\n",
            "download: 1\n",
            "thank: 1\n"
          ]
        }
      ],
      "source": [
        "from collections import Counter\n",
        "\n",
        "# Assuming all_filtered_words is the list of filtered words\n",
        "all_word_freq = Counter(all_filtered_words)\n",
        "\n",
        "# Sort the word frequencies in descending order\n",
        "sorted_word_freq = all_word_freq.most_common()\n",
        "\n",
        "# Display the sorted frequencies\n",
        "for word, freq in sorted_word_freq:\n",
        "    print(f\"{word}: {freq}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-6FZ42sNdwpz",
        "outputId": "d2f9ef0d-ac3a-4e65-ac4c-8b97df2081d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "words: 22\n",
            "task: 20\n",
            "band: 15\n"
          ]
        }
      ],
      "source": [
        "top_keywords=[]\n",
        "i=1\n",
        "for word, freq in most_common:\n",
        "    if i>3:\n",
        "      break\n",
        "    i+=1\n",
        "    top_keywords.append(word)\n",
        "    print(f\"{word}: {freq}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t6Kwnf0Gb_Wh"
      },
      "outputs": [],
      "source": [
        "highlighted_subtitle_files = search_words_in_transcription(\"subtitle_json.json\", top_keywords)\n",
        "\n",
        "# Extract highlighted sections from the subtitle file\n",
        "highlighted_sections = extract_highlighted_sections(highlighted_subtitle_files)\n",
        "\n",
        "# Create highlight video using the extracted sections\n",
        "create_highlight_video(\"video.mp4\", highlighted_sections)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JC5xza_Tsp98"
      },
      "source": [
        "# Comment Analysis and video create"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tFsIGj0hsowc",
        "outputId": "f45854a0-b854-4a0c-9291-8c315543bc70"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Comments have been written to /content/youtube_comments-1.txt\n"
          ]
        }
      ],
      "source": [
        "nest_asyncio.apply()  # Apply the patch to allow nested event loops\n",
        "\n",
        "async def get_youtube_comments(video_url):\n",
        "    async with async_playwright() as p:\n",
        "        browser = await p.chromium.launch(headless=True)\n",
        "        page = await browser.new_page()\n",
        "        await page.goto(video_url)\n",
        "\n",
        "        # Scroll to load comments\n",
        "        for _ in range(15):  # Scroll multiple times to load more comments\n",
        "            await page.evaluate('window.scrollTo(0, document.documentElement.scrollHeight);')\n",
        "            await page.wait_for_timeout(2000)  # Wait for comments to load\n",
        "\n",
        "        # Extract comments\n",
        "        comments = await page.evaluate('''Array.from(document.querySelectorAll('#content-text')).map(el => el.innerText)''')\n",
        "\n",
        "        await browser.close()\n",
        "        return comments\n",
        "\n",
        "# Define the video URL\n",
        "video_url = 'https://www.youtube.com/watch?v=VQluL1IRDbY'  # Replace with the actual video URL\n",
        "\n",
        "# Run the scraping function\n",
        "loop = asyncio.get_event_loop()\n",
        "comments = loop.run_until_complete(get_youtube_comments(video_url))\n",
        "\n",
        "# Define the output file path\n",
        "output_file = '/content/youtube_comments-1.txt'\n",
        "\n",
        "# Write comments to the file\n",
        "with open(output_file, 'w') as file:\n",
        "    for idx, comment in enumerate(comments):\n",
        "        file.write(f\"Comment {idx + 1}: {comment}\\n\")\n",
        "\n",
        "print(f\"Comments have been written to {output_file}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "UI1UOA1ZsouI",
        "outputId": "ddba0d60-0f44-477d-da2f-d063c7210ba8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Comment 1: I've studied your videos and achieved Band 8 in Writing. Well done and thank you\n",
            "Comment 2: I scored 7.5 overall and 7.5 in writing as well. I took computer based IELTS on the 12th of this month.\n",
            "Comment 3: Got overall 8 band in just 3 day prep, your videos helped!\n",
            "Comment 4: this video helps me to analyze those graphs and give me idea for my upcoming ielts exam\n",
            "Comment 5: I can't thank you enough.The way you made our preparation for IELTS easy is amazing.\n",
            "Comment 6: Hi Asiya! I can't thank you enough for your amazing content. I got an overall score of 8 with 7.5 in writing in computer based IELTS Academic. Took the test on 24th October. Once again thank you so much. Much love!\n",
            "Comment 7: Prepared for my academic exam using your videos, managed to score L8.5,R7.5 W7, S8. Thank you\n",
            "Comment 8: Hi first of all a big thank u from my heart..... I hav passed my Ielts with overall 7.5 with l-8, S 7, Reading -7.5 and W 7....without u nothing would hav been possible... Jst watched ur videos for a couple of days n am passed love from india, kerala\n",
            "Comment 9: Got my results last week as follows:\n",
            "\n",
            "L: 9.0 R: 8.5 W: 7.5 S: 7.5\n",
            "Overall band score: 8\n",
            "\n",
            "thank you very much for your help!\n",
            "Comment 10: The two graphical data represent the alterations in the number of houses with electrical gadgets and the extent of time spent doing chores by each household per week in a nation from 1920 to 2019.\n",
            "\n",
            "Overall, the usage of appliances fluctuated which significantly influenced the time spent in each household for the housework.\n",
            "\n",
            "Both, the number of refrigerators and vacuum cleaners show a positive growth between 1920 and 2019, but, refrigerators dominate the chart by going from 0 percent in 1920 to 100 percent in 2000 and plateauing to 2019. A similar trajectory was observed in the case of vacuum cleaners, starting at 30 percent in 1920 and showing an increment of 70 percent on reaching the year 2019. However, washing machines had a downfall of 10 percent between 1960 and 1980 after consistently escalating from  40 percent to 70 percent between 1920 and 1960, and eventually peaking at just above 70 percent in 2019.\n",
            "\n",
            "The number of hours used to complete house tasks had a steady decline from 50 hours per week to a little over 10 hours a week between 1920 and 1960, this decline paced slowly between 1960 and 2019 with a final reading of 10 hours a week in 2019.\n",
            "\n",
            "this is what I wrote can you please give me a rough approximation of the band score I'd get with this type of essay\n",
            "Comment 11: Can you please make a video on Task 1 using a diagram as an example please. I am taking my IELTS on November 4 so it will be really helpful. I'm going through all your videos and free materials that you are providing on the channel as I'm not able to afford for paid course. I'm just trying to prepare myself with the available source rather than complaining. Please I hope you understand. It means a lot.\n",
            "Comment 12: Just came back to say thankyou so much!\n",
            "I just scored an overall 7.5 band with just 2 days of study!\n",
            "Comment 13: Thankssss a lot of, for me to go through the questions’ categories in task 1!!\n",
            "Comment 14: Thanks, so much! Have been using your content to teach my students the best strategies to ace their IELTS test. Kisses from Portugal!\n",
            "Comment 15: wtf this is so hard for what???\n",
            "Comment 16: Wish me luckkk tomorrow is my test\n",
            "Comment 17: I just finished my speaking rest now, it wasn’t bad. I’m about to go in for the rest. Wish me luck\n",
            "Comment 18: if i ever happen to meet u mam, i will surely pay u fees, u deserve it. i had 0 clue of this topic , i took notes from this lecture . and had to spend 45 minutes to understand and analyze. trust me at the end m at a satisfactory position wrt task 1 academic. thanks a ton, may God always bless u .\n",
            "Comment 19: Why do you use present tense (e.g. \"has been maintained\", for the first line graph) when the time period provided for the data is clearly in the past?\n",
            "Comment 20: exceptionally good information, thank you very much.\n",
            "Comment 21: Thanks to you I scored a overall band 7.5 with L 8.5, R 8, W 6.5 and S 6.5 in just 15 days preparation\n",
            "Comment 22: Hi there am very pleased with your contribution towards my IELTS journey. It was successful by God's Grace, Blessed be you.\n",
            "Comment 23: Hi Asiya, thank you for the amazing tutorials! A friend recommended your page to me whilst I was preparing for my IELTS - I wanted someone who explained the format and the logical ways to organise my thoughts into a flow for the exam, so grateful for your content! It really helped me especially for writing which is the one I wanted to know how to analyse and I got a band score of 8.5! Thanks a lot Asiya, I’ll be recommending your page to others too\n",
            "Comment 24: I'll be taking the test in a few minutes omg wish I can do my best\n",
            "Comment 25: Somebody help me to explain how to do reading, writing and speaking I do alot of mistakes in writing and speaking. What should I do?\n",
            "Comment 26: May you acheive success in each part of your life.\n",
            "Comment 27: Thank you for guidance.. this really helped me with my test.\n",
            "Comment 28: I'm taking my test next week (all 4) and I have one week to prepare wish me luck\n",
            "Comment 29: In the recycling diagram , the second sentence should not indicate any details but here there were details.\n",
            "Comment 30: QUESTION what would it be a good source of vocabulary?\n",
            "Comment 31: I’ve booked my IELTS on 14th of October and scored band 7,5. Before that I’ve already booked it for 20th October but to meet university deadline I had to rebook it for an earlier date. I couldn’t cancel the first booking therefore I had speaking today with the same questions in part1. I feel so miserable, I can communicate easily but when I become nervous I forget everything, I just want to kill myself, don’t know what to do, I’ve ruined everything because of my anxiety, don’t know how to cope with that\n",
            "Comment 32: my exam is tomorrow. Wish me luck. I hope coming here to share my happiness.\n",
            "I got 7.5 score.who\n",
            "Comment 33: The two line graphs show the relationship between the percentage of owning the electric devices and the hours of house chores over a century in a country.\n",
            "\n",
            "Overall, the more appliances people hade, the less hours they work at home. Over the given period, the two graphs are inversely proportional to each other.\n",
            "Comment 34: Thank you Asia, your explanations are so much helpful, but I have noticed a small incorrect phrase its (Over one hundred years) not (over a one hundred year), I hope you make it correct.\n",
            "Comment 35: Immensely helpful! Thank you so much!\n",
            "Comment 36: this was our task when we were having a sample test to become an ielts teacher ahahha memories bring back hahah\n",
            "Comment 37: Very educative and impressive, help me reading and speaking\n",
            "Comment 38: Thank you for your support and a\n",
            "Information about ielts mam\n",
            "Comment 39: I really appreciate your videos.I actually spent around five days watching your videos, and on October 25th, I took my computer-based test. I received a 7 band score overall—L-8.5 R-7.5 W-6.5 S-6.I just watched videos for five days. I wish I had watched your videos sooner.\n",
            "Comment 40: Thanks for sharing well information.\n",
            "Comment 41: Dec 09 2023 will be my test day. Wish me a goodluck\n",
            "Comment 42: You are literally AMAZING!!!\n",
            "Comment 43: Hello, Mrs Asiya\n",
            "\n",
            "Firstly, I'd like to commend you on your video, that for the first time really attracted me.Your clear explanations and structured approach undoubtedly provide valuable guidance for test takers. Here are some thoughts and suggestions that could enhance the effectiveness and reach of your video:\n",
            "\n",
            "Your skills that I appreciate\n",
            "\n",
            "1. Clarity and Pace: Your presentation was clear and well-paced. You allowed enough time for viewers to understand each before moving on, which is crucial for learners who are not native English speakers.\n",
            "\n",
            "2. Use of Examples: The inclusion of specific examples on how to approach different types of charts and graphs was particularly helpful. Demonstrating these techniques in real-time adds practical value for viewers preparing for the exam.\n",
            "\n",
            "3. Visual Aids: The visual aids used to highlight key points and strategies were effective and maintained viewer engagement. The annotations on sample charts were especially useful in explaining how to interpret data accurately.\n",
            "\n",
            "Some points that should be improved in my view\n",
            "\n",
            "1. Additional Resources: Providing links to additional resources for further practice (like practice datasets or more sample responses) could be beneficial. Viewers often look to expand their learning with more material, and guiding them to trusted sources would be advantageous.\n",
            "\n",
            "2. Accessibility Features: To enhance accessibility, consider adding subtitles in multiple languages, or at least in English, to assist non-native speakers in following along more effectively. Additionally, a voiceover explaining the key points could also help those who may struggle with reading on-screen text.\n",
            "\n",
            "Overall, your video serves as a strong educational tool for individuals preparing for the IELTS writing task. Implementing some of these suggestions could help you broaden your audience and increase the educational impact of your content. Keep up the great work!\n",
            "\n",
            "Best regards,\n",
            "Dilyafruz\n",
            "Comment 44: Thanks a lot for sharing your knowledge and experience, Asia Miart\n",
            "Comment 45: At 11:40 its 40% increase in students numbers not 60%. Please make correction.\n",
            "Comment 46: Thank you fastrack ielts, I got a band 7.5 in my writing and 7 in my speaking\n",
            "Comment 47: thank you for making this video\n",
            "Comment 48: I would have used \"appliances\" not \"devices\" in your essay or sentences since it's talking about appliances but I suppose nowadays a device can also be an appliance?\n",
            "Comment 49: i paid to $751 IELTS preparation course  but got notting , no trick just doing exam   i should have found you first thank you so much\n",
            "Comment 50: When I watch your video everything seams like easy\n",
            "Comment 51: I use a netflix account so please tell me that what tipe of movie will be useful for my listing section,,\n",
            "\n",
            "\n",
            "1,,Action\n",
            "2,,Anime\n",
            "3,,Comedies\n",
            "4,,Crime\n",
            "\n",
            "5,,Documentaries\n",
            "6,,Dramas\n",
            "7,,Earth Month\n",
            "8,,Fantasy\n",
            "\n",
            "9,,Horror\n",
            "10,,Kids & Family\n",
            "11,,Music & Musicals\n",
            "12,,Reality\n",
            "\n",
            "13,,Romance\n",
            "14,,Sci-Fi\n",
            "15,,Stan Up\n",
            "16,,Thrillers\n",
            "Comment 52: In the part of lexical resource , i don't understand why we use present perfect in that period of time . someone enlightens me please.\n",
            "Comment 53: Thank you so much Asiya! I got an overall band 8 on my first attempt after about two weeks of preparation and your videos helped a lot.\n",
            "L - 8.5\n",
            "R - 8.5\n",
            "W - 7\n",
            "S - 8.5\n",
            "Comment 54: Taking IELTS Academic tomorrow! Great video, I'll come back and let ya'll know how it went!\n",
            "Comment 55: Can anyone share the English vocabulary for representing line charts/Grapes etc. or at least this paragraph which explained above.\n",
            "Comment 56:  help me to learn more about writing in overview and body one and body two in task one\n",
            "Comment 57: I have an academic IELTS test tomorrow and my English is really bad! need help\n",
            "Comment 58: Thank you so much\n",
            "Comment 59: Good way to explain.\n",
            "Comment 60: accidentally stumbled upon her, her beauty and way of conversing makes me low key do better than I was gonna, is this simping or just teacher effect?\n",
            "Comment 61: Thank you so much. You are so good at what you do\n",
            "Comment 62: my test is 24th August,my current score is 5.5. I have 160 days for preparing, how can i achieve 7+? If you have advice, please share it\n",
            "Comment 63: Mam, thank you kindly, keep me in your prayer\n",
            "Comment 64: My exam is tomorrow wish me luck as i am so nervous and can't sleep watching this video now\n",
            "Comment 65: thankyou maam  u helped a lot\n",
            "Comment 66: Today is my ielts exam  pray for myself\n",
            "Comment 67: Are all the real tests in the Cambridge books? Is it the same as the test?\n",
            "Comment 68: Do you help with reading aswell?\n",
            "Comment 69: Help me in reading\n",
            "Comment 70: thanks for sharing this video\n",
            "Comment 71: You are the best Assiya\n",
            "Comment 72: Thank you.\n",
            "Comment 73: Hi, I noticed that the data in the graph  of sample 1 only goes up to 2019. Could you please explain how the answer how the answer references 2020?\n",
            "Comment 74: Please share me, link for ielts reading section : match each statement with the correct researchers\n",
            "Comment 75: I know i seem stupid but guys what this pictures called?\n",
            "Comment 76: Guy’s i cant be more anxious about my test.If i fail, my school will be refusing me. I have to get 5.5 in each sections and 6 overall…\n",
            "Comment 77: Thank youuuu\n",
            "Comment 78: Can we not give reasons as to why certain changes in the data happened in academic writing task 1?? How much would it throw us down if we said \"the data hints at how parents may have prohibited their children from consuming too many harmful and sugary foods\" (as an example of course) ? Would it lower or score for task 1 to a 5 or could we still get a 6? Or is it just that it affects the task achievement component of the 4 criteria assessed?\n",
            "Comment 79: Mam all  types variation of task 1 acedmic\n",
            "Comment 80: Thank you fairy to teach\n",
            "Comment 81: great guiding\n",
            "Comment 82: nice job! thanks!\n",
            "40% not 60%)\n",
            "Comment 83: Hi Asiya ! I hope u r doing good. Please let me know that why there was no overview or introductory paragraph for maps question.\n",
            "Comment 84: Can anyone help me from which website we can practice monk test.\n",
            "Comment 85: Should we suggest reasons for the data shown?\n",
            "Comment 86: As possible ( what is mean Band 9.0)\n",
            "Comment 87: Asiya is gorgeous and amazing altogether!\n",
            "Comment 88: mam, please make a video on writing task 2 for general training.\n",
            "Comment 89: hello,\n",
            "how can i get it task 1 vocabulary?\n",
            "Comment 90: Is it ok to write an overview at the end of the report?\n",
            "Comment 91: My exam is on the 25th September 2023 and I still don’t understand anything about this academic writing task 1\n",
            "Comment 92: Please share vocabulary sheet that you've made\n",
            "Comment 93: Hi ma'am please give me the link of your first video I want start from the first but I couldn't find your first video\n",
            "Thanks\n",
            "Comment 94: Which one is better?? PBT or CBT????\n",
            "Comment 95: It's difficult  help me I used simple words\n",
            "Comment 96: Pls can you write the ielts in capital letters in the computer based ielts?\n",
            "Comment 97: There is nothing that says the two graphs are related.  How can you say that\n",
            "Comment 98: Great\n",
            "Comment 99: 11.20 : the predicted rise would be 40%\n",
            "Comment 100: Hi mam. I'm your new subscriber\n"
          ]
        }
      ],
      "source": [
        "# Define the file path\n",
        "input_file = '/content/youtube_comments-1.txt'  # Replace with your file path\n",
        "\n",
        "# Read the contents of the file\n",
        "with open(input_file, 'r') as file:\n",
        "    comments = file.readlines()\n",
        "\n",
        "# Print the contents of the file\n",
        "for line in comments:\n",
        "    print(line.strip())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dNKnGtzBtE57",
        "outputId": "2f2d7831-6d0e-4ae8-ba6d-364ca9e984f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CSV file 'comments.csv' created successfully!\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Read comments from the text file\n",
        "with open('/content/youtube_comments-1.txt', 'r') as file:\n",
        "    lines = file.readlines()\n",
        "\n",
        "# Filter and prepare data for CSV\n",
        "data = []\n",
        "for line in lines:\n",
        "    if line.startswith(\"Comment\"):\n",
        "        # Extract the comment ID and text\n",
        "        parts = line.split(':', 1)\n",
        "        if len(parts) == 2:\n",
        "            comment_id = parts[0].strip()\n",
        "            comment_text = parts[1].strip()\n",
        "            if comment_text:  # Ensure there is text after the colon\n",
        "                # Append only if it starts with \"comment-\"\n",
        "                data.append((comment_id, comment_text))\n",
        "\n",
        "# Write data to CSV\n",
        "with open('comments.csv', 'w', newline='', encoding='utf-8') as csvfile:\n",
        "    writer = csv.writer(csvfile)\n",
        "    writer.writerow(['ID', 'Comment'])  # Write header\n",
        "    writer.writerows(data)  # Write data rows\n",
        "\n",
        "print(\"CSV file 'comments.csv' created successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "KVgSF8SytO2z",
        "outputId": "bd7efef6-1450-40ba-eeda-16021fbfcf61"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 100,\n  \"fields\": [\n    {\n      \"column\": \"ID\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 100,\n        \"samples\": [\n          \"Comment 84\",\n          \"Comment 54\",\n          \"Comment 71\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Comment\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 100,\n        \"samples\": [\n          \"Can anyone help me from which website we can practice monk test.\",\n          \"Taking IELTS Academic tomorrow! Great video, I'll come back and let ya'll know how it went!\",\n          \"You are the best Assiya\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-1ed58a27-003d-47eb-bd6c-214cf47e1c12\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Comment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Comment 1</td>\n",
              "      <td>I've studied your videos and achieved Band 8 i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Comment 2</td>\n",
              "      <td>I scored 7.5 overall and 7.5 in writing as wel...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Comment 3</td>\n",
              "      <td>Got overall 8 band in just 3 day prep, your vi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Comment 4</td>\n",
              "      <td>this video helps me to analyze those graphs an...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Comment 5</td>\n",
              "      <td>I can't thank you enough.The way you made our ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>Comment 96</td>\n",
              "      <td>Pls can you write the ielts in capital letters...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>Comment 97</td>\n",
              "      <td>There is nothing that says the two graphs are ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>Comment 98</td>\n",
              "      <td>Great</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>Comment 99</td>\n",
              "      <td>11.20 : the predicted rise would be 40%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>Comment 100</td>\n",
              "      <td>Hi mam. I'm your new subscriber</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1ed58a27-003d-47eb-bd6c-214cf47e1c12')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1ed58a27-003d-47eb-bd6c-214cf47e1c12 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1ed58a27-003d-47eb-bd6c-214cf47e1c12');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-729032fb-98d7-4e13-9143-4257fe15847c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-729032fb-98d7-4e13-9143-4257fe15847c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-729032fb-98d7-4e13-9143-4257fe15847c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_245074ed-03ed-4279-b252-5d1b3550a067\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_245074ed-03ed-4279-b252-5d1b3550a067 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "             ID                                            Comment\n",
              "0     Comment 1  I've studied your videos and achieved Band 8 i...\n",
              "1     Comment 2  I scored 7.5 overall and 7.5 in writing as wel...\n",
              "2     Comment 3  Got overall 8 band in just 3 day prep, your vi...\n",
              "3     Comment 4  this video helps me to analyze those graphs an...\n",
              "4     Comment 5  I can't thank you enough.The way you made our ...\n",
              "..          ...                                                ...\n",
              "95   Comment 96  Pls can you write the ielts in capital letters...\n",
              "96   Comment 97  There is nothing that says the two graphs are ...\n",
              "97   Comment 98                                              Great\n",
              "98   Comment 99            11.20 : the predicted rise would be 40%\n",
              "99  Comment 100                    Hi mam. I'm your new subscriber\n",
              "\n",
              "[100 rows x 2 columns]"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "# Load CSV file into DataFrame\n",
        "csv_filename = 'comments.csv'\n",
        "df=pd.read_csv(csv_filename)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329,
          "referenced_widgets": [
            "e29163acc6664871a4918c3b6484fff6",
            "9a6f24eaebee4fec8db58915b4a0641f",
            "0f6a8605ce4d4e0b90f639b7288fbb09",
            "22febc8b467c4e7280b9b795a6c3648d",
            "abbf6e850ab941f09543d2ed1ee02768",
            "663ff4167e9746b290a010acfb68df35",
            "f185a7b8c9e347c6a473f529030e02fd",
            "a1584e5773df4cdea7237e9b17956c50",
            "9437f2198a4f45b294ec0cc79c7231fd",
            "e7ddbbb54a5f4dbcb0a3866c6595b71a",
            "7fdef8d7dae4451e8821f8ced7f0e80d",
            "7029ff04170746e7b4d20888f7623630",
            "06dc12ea8f354ea589e52d82ed82728a",
            "6b7dac8fc9bb4082a488ebf072ac22f8",
            "7a5c2c5f098b47ceb99b939fc0209769",
            "1f946b9d8a764c0cb948b455e4d20f77",
            "b1eb69189c234983b9fc04d0d1afab8f",
            "1a5bc91c5e3840b4aed34f451fd58dfc",
            "93ea605791104b3894a73e5a9774176f",
            "16fc4dc7fab241d1baf2aa9a70072085",
            "502a2a74e92a4946b784313e98b18887",
            "159a2ec105bb400dadd6a6b63ea7e205",
            "2bbeebf55ab945e69cf2caa274c9241d",
            "7c27111617914b19af0a2246c672e09f",
            "62548682675a4724aa938c0b0b7c1c94",
            "ef72128b10e446ca86b9f697664fcc4d",
            "14a82861d8104688aad79cee9bf1ec4c",
            "894e5e4aaa824f0ab1e20522e9a9511f",
            "b74aec59597c4e028ea70b052a8aa96a",
            "186a0bb3891e4e3982984582ee462c65",
            "bce93a5756a64099a84e0ff3994abfb9",
            "1eb8dfcc83714abba5da8d65263b3f8e",
            "3fcfa4825beb40d89f9686ea56786e48",
            "f4c89b8d5d444b41a0bcb71e40712f28",
            "9af7236227644e7cacbbca3ec98b8600",
            "aafe4696b7cd4051880ae19522a07e33",
            "8b591aa5787c4801b17dcc92c3418ff4",
            "7d4b60a35aac4255a6be3185515fbfba",
            "76bf36702052474c846aa6bfceceb95f",
            "1273e50921c64617ac18bebdc0c33b55",
            "95ce38172b0243ffa90bb1802bc9e5fb",
            "80623e1e4c8048e3a49b35cdcddf3e41",
            "6b02f03e33d445fc9a77ddf2b6363b6b",
            "f129fe54962b4cf9807c161fce47db0b"
          ]
        },
        "id": "DZlyN3RGtSEr",
        "outputId": "854a8584-cbe9-43da-c351-e0a1634fdf3a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "WARNING:py.warnings:/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e29163acc6664871a4918c3b6484fff6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7029ff04170746e7b4d20888f7623630",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2bbeebf55ab945e69cf2caa274c9241d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f4c89b8d5d444b41a0bcb71e40712f28",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "# Load the sentiment analysis model\n",
        "sentiment_pipeline = pipeline('sentiment-analysis')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z7RU1e48taz1",
        "outputId": "dae70c92-e787-41c2-ad21-f55ac08449ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Positive Comments:\n",
            "             ID                                            Comment\n",
            "0     Comment 1  I've studied your videos and achieved Band 8 i...\n",
            "1     Comment 2  I scored 7.5 overall and 7.5 in writing as wel...\n",
            "2     Comment 3  Got overall 8 band in just 3 day prep, your vi...\n",
            "3     Comment 4  this video helps me to analyze those graphs an...\n",
            "4     Comment 5  I can't thank you enough.The way you made our ...\n",
            "..          ...                                                ...\n",
            "89   Comment 90  Is it ok to write an overview at the end of th...\n",
            "91   Comment 92     Please share vocabulary sheet that you've made\n",
            "97   Comment 98                                              Great\n",
            "98   Comment 99            11.20 : the predicted rise would be 40%\n",
            "99  Comment 100                    Hi mam. I'm your new subscriber\n",
            "\n",
            "[61 rows x 2 columns]\n",
            "\n",
            "Negative Comments:\n",
            "            ID                                            Comment\n",
            "9   Comment 10  The two graphical data represent the alteratio...\n",
            "14  Comment 15                    wtf this is so hard for what???\n",
            "15  Comment 16                 Wish me luckkk tomorrow is my test\n",
            "17  Comment 18  if i ever happen to meet u mam, i will surely ...\n",
            "18  Comment 19  Why do you use present tense (e.g. \"has been m...\n",
            "23  Comment 24  I'll be taking the test in a few minutes omg w...\n",
            "24  Comment 25  Somebody help me to explain how to do reading,...\n",
            "28  Comment 29  In the recycling diagram , the second sentence...\n",
            "29  Comment 30  QUESTION what would it be a good source of voc...\n",
            "30  Comment 31  I’ve booked my IELTS on 14th of October and sc...\n",
            "32  Comment 33  The two line graphs show the relationship betw...\n",
            "35  Comment 36  this was our task when we were having a sample...\n",
            "38  Comment 39  I really appreciate your videos.I actually spe...\n",
            "44  Comment 45  At 11:40 its 40% increase in students numbers ...\n",
            "47  Comment 48  I would have used \"appliances\" not \"devices\" i...\n",
            "49  Comment 50  When I watch your video everything seams like ...\n",
            "50  Comment 51  I use a netflix account so please tell me that...\n",
            "54  Comment 55  Can anyone share the English vocabulary for re...\n",
            "56  Comment 57  I have an academic IELTS test tomorrow and my ...\n",
            "59  Comment 60  accidentally stumbled upon her, her beauty and...\n",
            "61  Comment 62  my test is 24th August,my current score is 5.5...\n",
            "65  Comment 66            Today is my ielts exam  pray for myself\n",
            "66  Comment 67  Are all the real tests in the Cambridge books?...\n",
            "67  Comment 68                   Do you help with reading aswell?\n",
            "72  Comment 73  Hi, I noticed that the data in the graph  of s...\n",
            "74  Comment 75  I know i seem stupid but guys what this pictur...\n",
            "75  Comment 76  Guy’s i cant be more anxious about my test.If ...\n",
            "77  Comment 78  Can we not give reasons as to why certain chan...\n",
            "78  Comment 79         Mam all  types variation of task 1 acedmic\n",
            "83  Comment 84  Can anyone help me from which website we can p...\n",
            "84  Comment 85      Should we suggest reasons for the data shown?\n",
            "85  Comment 86               As possible ( what is mean Band 9.0)\n",
            "87  Comment 88  mam, please make a video on writing task 2 for...\n",
            "90  Comment 91  My exam is on the 25th September 2023 and I st...\n",
            "92  Comment 93  Hi ma'am please give me the link of your first...\n",
            "93  Comment 94               Which one is better?? PBT or CBT????\n",
            "94  Comment 95        It's difficult  help me I used simple words\n",
            "95  Comment 96  Pls can you write the ielts in capital letters...\n",
            "96  Comment 97  There is nothing that says the two graphs are ...\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Load CSV file into DataFrame\n",
        "csv_filename = 'comments.csv'\n",
        "df = pd.read_csv(csv_filename)\n",
        "\n",
        "# Function to classify sentiment\n",
        "def classify_sentiment(text):\n",
        "    result = sentiment_pipeline(text)\n",
        "    label = result[0]['label']\n",
        "    return 'Positive' if label == 'POSITIVE' else 'Negative'\n",
        "\n",
        "# Apply sentiment analysis to the 'Comment' column\n",
        "df['Sentiment'] = df['Comment'].apply(classify_sentiment)\n",
        "\n",
        "# Filter for positive and negative comments\n",
        "positive_comments = df[df['Sentiment'] == 'Positive']\n",
        "negative_comments = df[df['Sentiment'] == 'Negative']\n",
        "\n",
        "# Print positive comments\n",
        "print(\"Positive Comments:\")\n",
        "print(positive_comments[['ID', 'Comment']])\n",
        "\n",
        "# Print negative comments (if needed)\n",
        "print(\"\\nNegative Comments:\")\n",
        "print(negative_comments[['ID', 'Comment']])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "_ZukSQ-ctbjE",
        "outputId": "ac4d9837-0496-480e-c04a-f306ba8a2398"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Comment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I've studied your videos and achieved Band 8 i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I scored 7.5 overall and 7.5 in writing as wel...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Got overall 8 band in just 3 day prep, your vi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>this video helps me to analyze those graphs an...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I can't thank you enough.The way you made our ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89</th>\n",
              "      <td>Is it ok to write an overview at the end of th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>91</th>\n",
              "      <td>Please share vocabulary sheet that you've made</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>Great</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>11.20 : the predicted rise would be 40%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>Hi mam. I'm your new subscriber</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>61 rows × 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ],
            "text/plain": [
              "0     I've studied your videos and achieved Band 8 i...\n",
              "1     I scored 7.5 overall and 7.5 in writing as wel...\n",
              "2     Got overall 8 band in just 3 day prep, your vi...\n",
              "3     this video helps me to analyze those graphs an...\n",
              "4     I can't thank you enough.The way you made our ...\n",
              "                            ...                        \n",
              "89    Is it ok to write an overview at the end of th...\n",
              "91       Please share vocabulary sheet that you've made\n",
              "97                                                Great\n",
              "98              11.20 : the predicted rise would be 40%\n",
              "99                      Hi mam. I'm your new subscriber\n",
              "Name: Comment, Length: 61, dtype: object"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "positive_comments['Comment']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "umpxhN6LtgXG",
        "outputId": "ea9e31bd-9e33-47e8-f8b5-80a6afd89bbe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top 5 words found in both all_common and subtitle.json:\n",
            "words: 22\n",
            "task: 20\n",
            "band: 15\n",
            "charts: 14\n",
            "data: 13\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        }
      ],
      "source": [
        "# Download required NLTK data\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "# Define POS tags for each part of speech\n",
        "POS_TAGS = {\n",
        "    'NN': 'Noun', 'NNS': 'Noun', 'NNP': 'Noun', 'NNPS': 'Noun',  # Nouns\n",
        "    'JJ': 'Adjective', 'JJR': 'Adjective', 'JJS': 'Adjective',   # Adjectives\n",
        "    'RB': 'Adverb', 'RBR': 'Adverb', 'RBS': 'Adverb',            # Adverbs\n",
        "    'VB': 'Verb', 'VBD': 'Verb', 'VBG': 'Verb', 'VBN': 'Verb', 'VBP': 'Verb', 'VBZ': 'Verb'  # Verbs\n",
        "}\n",
        "\n",
        "# Auxiliary verbs and adverbs to exclude\n",
        "auxiliary_verbs = set([\n",
        "    'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being',\n",
        "    'have', 'has', 'had', 'having',\n",
        "    'do', 'does', 'did', 'doing', \"'s\", \"'m\", \"'re\", \"n't\"\n",
        "])\n",
        "specific_adverbs_to_exclude = set([\n",
        "    'so', \"n't\", 'just', 'right', 'not', 'here', 'maybe', 'then',\n",
        "    'often', 'always', 'never', 'rarely',\n",
        "    'very', 'too', 'quite',\n",
        "    'everywhere', 'nowhere', 'somewhere', 'anywhere'\n",
        "])\n",
        "\n",
        "# Function to filter and count words by POS tag\n",
        "def filter_words_by_pos(tagged_tokens, pos_tag_prefix):\n",
        "    return [word.lower() for word, tag in tagged_tokens if tag.startswith(pos_tag_prefix)]\n",
        "\n",
        "# Function to remove unwanted auxiliary verbs and specific adverbs\n",
        "def remove_unwanted_words(words):\n",
        "    return [word for word in words if word not in auxiliary_verbs and word not in specific_adverbs_to_exclude]\n",
        "\n",
        "# Function to extract text, tokenize, and count word frequencies\n",
        "def extract_and_analyze_words(json_file, top_n=5):\n",
        "    with open(json_file, 'r') as file:\n",
        "        data = json.load(file)\n",
        "\n",
        "    # Extract text from JSON\n",
        "    text = ' '.join(segment['text'] for segment in data)\n",
        "\n",
        "    # Tokenize and POS tagging\n",
        "    tokens = word_tokenize(text)\n",
        "    tagged_tokens = pos_tag(tokens)\n",
        "\n",
        "    # Aggregate filtered words from all POS tags\n",
        "    all_filtered_words = []\n",
        "    for pos_tag_key in POS_TAGS:\n",
        "        filtered_words = filter_words_by_pos(tagged_tokens, pos_tag_key)\n",
        "        filtered_words = remove_unwanted_words(filtered_words)\n",
        "        all_filtered_words.extend(filtered_words)\n",
        "\n",
        "    # Count frequencies of all filtered words\n",
        "    word_freq = Counter(all_filtered_words)\n",
        "\n",
        "    # Return the top N most frequent words\n",
        "    return word_freq.most_common(top_n)\n",
        "\n",
        "# Call the function and extract all words\n",
        "subtitle_words = extract_and_analyze_words('/content/subtitle_json.json', top_n=None)\n",
        "\n",
        "# Convert subtitle_words list of tuples into a set for faster lookup\n",
        "subtitle_words_set = set(word for word, freq in subtitle_words)\n",
        "\n",
        "all_common = all_word_freq.most_common()\n",
        "# Filter the top 5 words from all_common that are present in subtitle.json\n",
        "top_5_words_in_subtitles = []\n",
        "for word, freq in all_common:\n",
        "    if word in subtitle_words_set:\n",
        "        top_5_words_in_subtitles.append((word, freq))\n",
        "    if len(top_5_words_in_subtitles) == 5:  # Stop after finding 5 words\n",
        "        break\n",
        "\n",
        "# Print the top 5 words\n",
        "print(\"Top 5 words found in both all_common and subtitle.json:\")\n",
        "for word, freq in top_5_words_in_subtitles:\n",
        "    print(f\"{word}: {freq}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4tUm8HItsxZ",
        "outputId": "b0647297-1130-4863-c4c5-c5131e9831a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['words', 'task', 'band', 'charts', 'data']\n"
          ]
        }
      ],
      "source": [
        "top_frq_word_present_video_and_comment=[]\n",
        "\n",
        "for word,frq in top_5_words_in_subtitles:\n",
        "  top_frq_word_present_video_and_comment.append(word)\n",
        "\n",
        "print(top_frq_word_present_video_and_comment)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e5pzFy1LcFSV"
      },
      "outputs": [],
      "source": [
        "highlighted_subtitle_files = search_words_in_transcription(\"subtitle_json.json\", top_frq_word_present_video_and_comment)\n",
        "# Extract highlighted sections from the subtitle file\n",
        "highlighted_sections = extract_highlighted_sections(highlighted_subtitle_files)\n",
        "# Create highlight video using the extracted sections\n",
        "create_highlight_video(\"video.mp4\", highlighted_sections)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "06dc12ea8f354ea589e52d82ed82728a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b1eb69189c234983b9fc04d0d1afab8f",
            "placeholder": "​",
            "style": "IPY_MODEL_1a5bc91c5e3840b4aed34f451fd58dfc",
            "value": "model.safetensors: 100%"
          }
        },
        "0f6a8605ce4d4e0b90f639b7288fbb09": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a1584e5773df4cdea7237e9b17956c50",
            "max": 629,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9437f2198a4f45b294ec0cc79c7231fd",
            "value": 629
          }
        },
        "1273e50921c64617ac18bebdc0c33b55": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "14a82861d8104688aad79cee9bf1ec4c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "159a2ec105bb400dadd6a6b63ea7e205": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "16fc4dc7fab241d1baf2aa9a70072085": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "186a0bb3891e4e3982984582ee462c65": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a5bc91c5e3840b4aed34f451fd58dfc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1eb8dfcc83714abba5da8d65263b3f8e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f946b9d8a764c0cb948b455e4d20f77": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22febc8b467c4e7280b9b795a6c3648d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e7ddbbb54a5f4dbcb0a3866c6595b71a",
            "placeholder": "​",
            "style": "IPY_MODEL_7fdef8d7dae4451e8821f8ced7f0e80d",
            "value": " 629/629 [00:00&lt;00:00, 30.3kB/s]"
          }
        },
        "2bbeebf55ab945e69cf2caa274c9241d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7c27111617914b19af0a2246c672e09f",
              "IPY_MODEL_62548682675a4724aa938c0b0b7c1c94",
              "IPY_MODEL_ef72128b10e446ca86b9f697664fcc4d"
            ],
            "layout": "IPY_MODEL_14a82861d8104688aad79cee9bf1ec4c"
          }
        },
        "3fcfa4825beb40d89f9686ea56786e48": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "502a2a74e92a4946b784313e98b18887": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62548682675a4724aa938c0b0b7c1c94": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_186a0bb3891e4e3982984582ee462c65",
            "max": 48,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bce93a5756a64099a84e0ff3994abfb9",
            "value": 48
          }
        },
        "663ff4167e9746b290a010acfb68df35": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b02f03e33d445fc9a77ddf2b6363b6b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b7dac8fc9bb4082a488ebf072ac22f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_93ea605791104b3894a73e5a9774176f",
            "max": 267832558,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_16fc4dc7fab241d1baf2aa9a70072085",
            "value": 267832558
          }
        },
        "7029ff04170746e7b4d20888f7623630": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_06dc12ea8f354ea589e52d82ed82728a",
              "IPY_MODEL_6b7dac8fc9bb4082a488ebf072ac22f8",
              "IPY_MODEL_7a5c2c5f098b47ceb99b939fc0209769"
            ],
            "layout": "IPY_MODEL_1f946b9d8a764c0cb948b455e4d20f77"
          }
        },
        "76bf36702052474c846aa6bfceceb95f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a5c2c5f098b47ceb99b939fc0209769": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_502a2a74e92a4946b784313e98b18887",
            "placeholder": "​",
            "style": "IPY_MODEL_159a2ec105bb400dadd6a6b63ea7e205",
            "value": " 268M/268M [00:01&lt;00:00, 141MB/s]"
          }
        },
        "7c27111617914b19af0a2246c672e09f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_894e5e4aaa824f0ab1e20522e9a9511f",
            "placeholder": "​",
            "style": "IPY_MODEL_b74aec59597c4e028ea70b052a8aa96a",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "7d4b60a35aac4255a6be3185515fbfba": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7fdef8d7dae4451e8821f8ced7f0e80d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "80623e1e4c8048e3a49b35cdcddf3e41": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "894e5e4aaa824f0ab1e20522e9a9511f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b591aa5787c4801b17dcc92c3418ff4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6b02f03e33d445fc9a77ddf2b6363b6b",
            "placeholder": "​",
            "style": "IPY_MODEL_f129fe54962b4cf9807c161fce47db0b",
            "value": " 232k/232k [00:00&lt;00:00, 4.16MB/s]"
          }
        },
        "93ea605791104b3894a73e5a9774176f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9437f2198a4f45b294ec0cc79c7231fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "95ce38172b0243ffa90bb1802bc9e5fb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a6f24eaebee4fec8db58915b4a0641f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_663ff4167e9746b290a010acfb68df35",
            "placeholder": "​",
            "style": "IPY_MODEL_f185a7b8c9e347c6a473f529030e02fd",
            "value": "config.json: 100%"
          }
        },
        "9af7236227644e7cacbbca3ec98b8600": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_76bf36702052474c846aa6bfceceb95f",
            "placeholder": "​",
            "style": "IPY_MODEL_1273e50921c64617ac18bebdc0c33b55",
            "value": "vocab.txt: 100%"
          }
        },
        "a1584e5773df4cdea7237e9b17956c50": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aafe4696b7cd4051880ae19522a07e33": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_95ce38172b0243ffa90bb1802bc9e5fb",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_80623e1e4c8048e3a49b35cdcddf3e41",
            "value": 231508
          }
        },
        "abbf6e850ab941f09543d2ed1ee02768": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b1eb69189c234983b9fc04d0d1afab8f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b74aec59597c4e028ea70b052a8aa96a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bce93a5756a64099a84e0ff3994abfb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e29163acc6664871a4918c3b6484fff6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9a6f24eaebee4fec8db58915b4a0641f",
              "IPY_MODEL_0f6a8605ce4d4e0b90f639b7288fbb09",
              "IPY_MODEL_22febc8b467c4e7280b9b795a6c3648d"
            ],
            "layout": "IPY_MODEL_abbf6e850ab941f09543d2ed1ee02768"
          }
        },
        "e7ddbbb54a5f4dbcb0a3866c6595b71a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef72128b10e446ca86b9f697664fcc4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1eb8dfcc83714abba5da8d65263b3f8e",
            "placeholder": "​",
            "style": "IPY_MODEL_3fcfa4825beb40d89f9686ea56786e48",
            "value": " 48.0/48.0 [00:00&lt;00:00, 2.65kB/s]"
          }
        },
        "f129fe54962b4cf9807c161fce47db0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f185a7b8c9e347c6a473f529030e02fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f4c89b8d5d444b41a0bcb71e40712f28": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9af7236227644e7cacbbca3ec98b8600",
              "IPY_MODEL_aafe4696b7cd4051880ae19522a07e33",
              "IPY_MODEL_8b591aa5787c4801b17dcc92c3418ff4"
            ],
            "layout": "IPY_MODEL_7d4b60a35aac4255a6be3185515fbfba"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
